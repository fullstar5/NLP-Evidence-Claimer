{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2024 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPitXZzTsyTn",
        "outputId": "ef561ddb-70cd-47fe-b133-e9321ebfa74c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_VcWPFMqtJ4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e7af7ad-f45d-4424-c75d-cc0ff2e9d49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import math\n",
        "import json\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ohyt_MA86_7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8fbe47b-a4c1-49a8-831e-aad2729b19e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "evidences = pd.read_json('/content/drive/MyDrive/nlp/data/evidence.json', orient='index')\n",
        "train_claims = pd.read_json('/content/drive/MyDrive/nlp/data/train-claims.json', orient='index')\n",
        "dev_claims = pd.read_json('/content/drive/MyDrive/nlp/data/dev-claims.json', orient='index')\n",
        "\n",
        "#update column names\n",
        "evidences.reset_index(inplace=True)\n",
        "evidences.columns = ['evidence_id', 'evidence_text']\n",
        "\n",
        "train_claims.reset_index(inplace=True)\n",
        "train_claims.rename(columns={'index': 'claim_id'}, inplace=True)\n",
        "\n",
        "dev_claims.reset_index(inplace=True)\n",
        "dev_claims.rename(columns={'index': 'claim_id'}, inplace=True)\n",
        "\n",
        "evidence_id = evidences['evidence_id']\n",
        "evidence_text = evidences['evidence_text']\n",
        "evidence_idx = evidences.index.tolist()\n",
        "\n",
        "evidence_id_dict = dict(zip(evidence_id, evidence_idx))\n",
        "\n",
        "train_claims_text = train_claims['claim_text']\n",
        "train_evidence_ids = train_claims['evidences']\n",
        "train_claim_labels = train_claims['claim_label']\n",
        "#map evidence_id to their corrosponding index for faster processing\n",
        "train_evidence_idxs = train_evidence_ids.apply(lambda x: [evidence_id_dict[evidence_id] for evidence_id in x])\n",
        "\n",
        "dev_claims_text = dev_claims['claim_text']\n",
        "dev_claim_labels = dev_claims['claim_label']\n",
        "dev_evidence_ids = dev_claims['evidences']\n",
        "dev_evidence_idxs = dev_evidence_ids.apply(lambda x: [evidence_id_dict[evidence_id] for evidence_id in x])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_claims = pd.read_json('/content/drive/MyDrive/nlp/data/test-claims-unlabelled.json', orient='index')\n",
        "test_claims.reset_index(inplace=True)\n",
        "test_claims.columns = ['claim_id', 'claim_text']\n",
        "test_claims_text = test_claims['claim_text']\n",
        "test_claims_id = test_claims['claim_id']"
      ],
      "metadata": {
        "id": "eEmCnO6TkYRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_claim_ids = dev_claims['claim_id']"
      ],
      "metadata": {
        "id": "YV2PK7ldyQao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "dev_evidence_indices = json.load(open(\"/content/drive/MyDrive/nlp/data/reranked_indices.json\", \"r\"))\n",
        "test_evidence_indices = json.load(open(\"/content/drive/MyDrive/nlp/data/test_reranked_indices.json\", \"r\"))"
      ],
      "metadata": {
        "id": "6eWAVRHbYL_j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_k_indices = [sublist[:5] if len(sublist) >= 5 else sublist + [None] * (5 - len(sublist)) for sublist in dev_evidence_indices]\n",
        "test_k_indices = [sublist[:5] if len(sublist) >= 5 else sublist + [None] * (5 - len(sublist)) for sublist in test_evidence_indices]"
      ],
      "metadata": {
        "id": "J12VT62YYjhd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "t9hCn0g-7Ae2"
      },
      "outputs": [],
      "source": [
        "tt = TweetTokenizer()\n",
        "stopwords = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_data(text):\n",
        "    tokens = tt.tokenize(text.lower())\n",
        "    return tokens\n",
        "\n",
        "train_claims_text_processed = train_claims_text.apply(preprocess_data)\n",
        "dev_claims_text_processed = dev_claims_text.apply(preprocess_data)\n",
        "evidence_text_processed = evidence_text.apply(preprocess_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(texts, min_freq=3):\n",
        "    # Count all the words\n",
        "    word_freq = Counter()\n",
        "    for text in texts:\n",
        "        word_freq.update(text)\n",
        "\n",
        "    # Start vocab from special tokens\n",
        "    vocab = OrderedDict({\n",
        "        \"<pad>\": 0,\n",
        "        \"<unk>\": 1,\n",
        "        \"<sos>\": 2,\n",
        "        \"<eos>\": 3\n",
        "    })\n",
        "    index = 4  # Start indexing from 4 because 0-3 are reserved for special tokens\n",
        "    for word, freq in word_freq.items():\n",
        "        if freq >= min_freq:  # Only include words that meet the frequency threshold\n",
        "            vocab[word] = index\n",
        "            index += 1\n",
        "\n",
        "    return vocab\n",
        "\n",
        "# Build vocabulary using only evidence texts and applying the frequency threshold\n",
        "vocab = build_vocab(evidence_text_processed, min_freq=3)"
      ],
      "metadata": {
        "id": "T_4DV847328f"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FHipd3IplZsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\n",
        "    \"REFUTES\": 0,\n",
        "    \"SUPPORTS\": 1,\n",
        "    \"NOT_ENOUGH_INFO\": 2,\n",
        "    \"DISPUTED\": 3\n",
        "}\n",
        "train_claim_labels = train_claims['claim_label'].map(label_map)\n",
        "dev_claim_labels = dev_claims['claim_label'].map(label_map)"
      ],
      "metadata": {
        "id": "99CY84id6ZJN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import random\n",
        "\n",
        "\n",
        "def text_to_indices(text, vocab):\n",
        "    return [vocab.get(word, vocab[\"<unk>\"]) for word in text]\n",
        "\n",
        "class ClaimEvidenceDataset(Dataset):\n",
        "    def __init__(self, claims, evidence_indices, evidences, claim_labels, vocab):\n",
        "        self.claims = claims\n",
        "        self.evidence_indices = evidence_indices\n",
        "        self.evidences = evidences\n",
        "        self.claim_labels = claim_labels\n",
        "        self.vocab = vocab\n",
        "        self.pairs = self.create_pairs()\n",
        "\n",
        "    def create_pairs(self):\n",
        "        pairs = []\n",
        "        for idx, claim in enumerate(self.claims):\n",
        "            label = self.claim_labels[idx]\n",
        "            if label == 3:  # Randomly assign 0 (REFUTES) or 1 (SUPPORTS) for \"DISPUTED\"\n",
        "                label = random.choice([0, 1, 2])\n",
        "            if label in [0, 1, 2]:  # Only consider REFUTES (0), SUPPORTS (1), and NOT ENOUGH INFO (2)\n",
        "                candidate_pos_indices = self.evidence_indices[idx]\n",
        "                relevant_evidences = [self.evidences[i] for i in candidate_pos_indices]\n",
        "                for evidence in relevant_evidences:\n",
        "                    pairs.append((claim, evidence, label))\n",
        "        return pairs\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        claim, evidence, label = self.pairs[idx]\n",
        "        claim_indices = text_to_indices(claim, self.vocab)\n",
        "        evidence_indices = text_to_indices(evidence, self.vocab)\n",
        "        claim_indices = [self.vocab[\"<sos>\"]] + claim_indices + [self.vocab[\"<eos>\"]]\n",
        "        evidence_indices = [self.vocab[\"<sos>\"]] + evidence_indices + [self.vocab[\"<eos>\"]]\n",
        "        return claim_indices, evidence_indices, label\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    claims, evidences, labels = zip(*batch)\n",
        "    claims_tensor = pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in claims], batch_first=True, padding_value=vocab[\"<pad>\"]).to(device)\n",
        "    evidences_tensor = pad_sequence([torch.tensor(seq, dtype=torch.long) for seq in evidences], batch_first=True, padding_value=vocab[\"<pad>\"]).to(device)\n",
        "    labels_tensor = torch.tensor(labels, dtype=torch.float).to(device)\n",
        "    return claims_tensor, evidences_tensor, labels_tensor\n",
        "\n",
        "\n",
        "# Prepare the data\n",
        "train_dataset = ClaimEvidenceDataset(train_claims_text_processed, train_evidence_idxs, evidence_text_processed, train_claim_labels, vocab)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate_fn)\n",
        "dev_dataset = ClaimEvidenceDataset(dev_claims_text_processed, dev_evidence_idxs, evidence_text_processed, dev_claim_labels, vocab)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate_fn)\n"
      ],
      "metadata": {
        "id": "viPwRuD789ab"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Bi-Directional GRU with Attention"
      ],
      "metadata": {
        "id": "QMmZlSPXoeM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ClaimEvidenceAttnModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, pad_idx, dropout=0.7):\n",
        "        super(ClaimEvidenceAttnModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 4, 3)  # Three classes\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.pad_idx = pad_idx\n",
        "        self.attn_claims = nn.Linear(hidden_dim * 2, 1, bias=False)\n",
        "        self.attn_evidences = nn.Linear(hidden_dim * 2, 1, bias=False)\n",
        "\n",
        "    def attention(self, gru_output, attn_layer, mask):\n",
        "        attn_energies = attn_layer(gru_output).squeeze(2)\n",
        "        attn_energies = attn_energies.masked_fill(mask.squeeze(2) == 0, -1e10)\n",
        "        attn_weights = F.softmax(attn_energies, dim=1)\n",
        "        context = torch.bmm(attn_weights.unsqueeze(1), gru_output).squeeze(1)\n",
        "        return context\n",
        "\n",
        "    def forward(self, claims, evidences):\n",
        "        embedded_claims = self.embedding(claims)\n",
        "        embedded_claims = self.dropout(embedded_claims)\n",
        "        claims_mask = (claims != self.pad_idx).unsqueeze(2).float()\n",
        "        embedded_claims *= claims_mask\n",
        "\n",
        "        gru_output_claims, _ = self.gru(embedded_claims)\n",
        "        claims_context = self.attention(gru_output_claims, self.attn_claims, claims_mask)\n",
        "\n",
        "        embedded_evidences = self.embedding(evidences)\n",
        "        embedded_evidences = self.dropout(embedded_evidences)\n",
        "        evidences_mask = (evidences != self.pad_idx).unsqueeze(2).float()\n",
        "        embedded_evidences *= evidences_mask\n",
        "\n",
        "        gru_output_evidences, _ = self.gru(embedded_evidences)\n",
        "        evidences_context = self.attention(gru_output_evidences, self.attn_evidences, evidences_mask)\n",
        "\n",
        "        combined_representation = torch.cat((claims_context, evidences_context), dim=1)\n",
        "        combined_representation = self.dropout(combined_representation)\n",
        "        logits = self.fc(combined_representation)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZahBwCH8BM-5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Transformer with self-attention"
      ],
      "metadata": {
        "id": "KFFwgHBBo69T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(-torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(0)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: torch.Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:, :token_embedding.size(1), :])\n",
        "\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: torch.Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, emb_size: int, num_heads: int, ff_hidden_size: int, dropout: float):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.attention = nn.MultiheadAttention(emb_size, num_heads, dropout=dropout)\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(emb_size, ff_hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_hidden_size, emb_size)\n",
        "        )\n",
        "        self.layernorm1 = nn.LayerNorm(emb_size)\n",
        "        self.layernorm2 = nn.LayerNorm(emb_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        attn_output, _ = self.attention(x, x, x, key_padding_mask=mask)\n",
        "        x = self.layernorm1(x + self.dropout(attn_output))\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.layernorm2(x + self.dropout(ff_output))\n",
        "        return x\n",
        "\n",
        "\n",
        "class ClaimVerificationTransformer(nn.Module):\n",
        "    def __init__(self, emb_size: int, vocab_size: int, num_heads: int, ff_hidden_size: int, num_encoder_layers: int, num_classes: int, dropout: float = 0.1, maxlen: int = 5000, pad_idx: int = 0):\n",
        "        super(ClaimVerificationTransformer, self).__init__()\n",
        "        self.embedding = TokenEmbedding(vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(emb_size, dropout, maxlen)\n",
        "        self.encoder_layers = nn.ModuleList([TransformerEncoder(emb_size, num_heads, ff_hidden_size, dropout) for _ in range(num_encoder_layers)])\n",
        "        self.fc = nn.Linear(emb_size, num_classes)\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def forward(self, claims: torch.Tensor, evidences: torch.Tensor):\n",
        "        # Embed and encode claims\n",
        "        embedded_claims = self.embedding(claims)\n",
        "        embedded_claims = self.positional_encoding(embedded_claims)\n",
        "        claims_mask = (claims == self.pad_idx)\n",
        "\n",
        "        for layer in self.encoder_layers:\n",
        "            embedded_claims = layer(embedded_claims.transpose(0, 1), claims_mask).transpose(0, 1)\n",
        "\n",
        "        claims_encoded = torch.mean(embedded_claims, dim=1)\n",
        "\n",
        "        # Embed and encode evidences\n",
        "        embedded_evidences = self.embedding(evidences)\n",
        "        embedded_evidences = self.positional_encoding(embedded_evidences)\n",
        "        evidences_mask = (evidences == self.pad_idx)\n",
        "\n",
        "        for layer in self.encoder_layers:\n",
        "            embedded_evidences = layer(embedded_evidences.transpose(0, 1), evidences_mask).transpose(0, 1)\n",
        "\n",
        "        evidences_encoded = torch.mean(embedded_evidences, dim=1)\n",
        "\n",
        "        # Combine claim and evidence representations\n",
        "        combined_representation = claims_encoded + evidences_encoded\n",
        "        logits = self.fc(combined_representation)\n",
        "        return logits\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4kE815v_zjIB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Training function"
      ],
      "metadata": {
        "id": "kP-DApvL2nlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, dev_loader, criterion, optimizer, device, num_epochs=10, grad_clip=1.0):\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for claims, evidences, labels in train_loader:\n",
        "            claims = claims.to(device)\n",
        "            evidences = evidences.to(device)\n",
        "            labels = labels.to(device).long()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(claims, evidences)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs} - Training Loss: {avg_train_loss}')\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for claims, evidences, labels in dev_loader:\n",
        "                claims = claims.to(device)\n",
        "                evidences = evidences.to(device)\n",
        "                labels = labels.to(device).long()\n",
        "\n",
        "                logits = model(claims, evidences)\n",
        "                val_loss = criterion(logits, labels)\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "                all_preds.extend(preds)\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(dev_loader)\n",
        "        accuracy = accuracy_score(all_labels, all_preds)\n",
        "        f1 = classification_report(all_labels, all_preds, target_names=['REFUTES', 'SUPPORTS', 'NOT_ENOUGH_INFO'], zero_division=0, output_dict=True)['macro avg']['f1-score']\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs} - Validation Loss: {avg_val_loss}')\n",
        "        print(f'Accuracy: {accuracy}')\n",
        "        print(f'F1 Score: {f1}')\n",
        "        print(classification_report(all_labels, all_preds, target_names=['REFUTES', 'SUPPORTS', 'NOT_ENOUGH_INFO'], zero_division=0))\n",
        "\n",
        "        scheduler.step(avg_val_loss)"
      ],
      "metadata": {
        "id": "ugU74--r2s-2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU Training"
      ],
      "metadata": {
        "id": "_TD8EPOs7qos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exclude the \"DISPUTED\" label from the calculations\n",
        "filtered_labels = train_claim_labels[train_claim_labels != 3]\n",
        "\n",
        "# Count the occurrences of each label\n",
        "class_counts = np.bincount(filtered_labels)\n",
        "total_samples = len(filtered_labels)\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = total_samples / (len(class_counts) * class_counts)\n",
        "# Convert the class weights to a tensor\n",
        "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
        "# Example usage with your existing dataset and dataloaders:\n",
        "train_dataset = ClaimEvidenceDataset(train_claims_text_processed, train_evidence_idxs, evidence_text_processed, train_claim_labels, vocab)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=custom_collate_fn)\n",
        "dev_dataset = ClaimEvidenceDataset(dev_claims_text_processed, dev_evidence_idxs, evidence_text_processed, dev_claim_labels, vocab)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate_fn)\n",
        "\n",
        "gru_model = ClaimEvidenceAttnModel(vocab_size=len(vocab), embedding_dim=300, hidden_dim=1024, pad_idx=vocab['<pad>'])\n",
        "#model = ClaimVerificationTransformer(emb_size=512, vocab_size=len(vocab), num_classes =3,dropout=0.7, pad_idx=vocab[\"<pad>\"])\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "optimizer = torch.optim.Adam(gru_model.parameters(), lr=0.0001)\n",
        "\n",
        "train_model(gru_model, train_loader, dev_loader, criterion, optimizer, device=device, num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ncpREQv2u-s",
        "outputId": "72877a2a-bd33-425b-9e50-dc83fed85cee"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Training Loss: 1.047194480895996\n",
            "Epoch 1/10 - Validation Loss: 1.086488664150238\n",
            "Accuracy: 0.4480651731160896\n",
            "F1 Score: 0.2062822315986873\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.00      0.00      0.00        92\n",
            "       SUPPORTS       0.00      0.00      0.00       179\n",
            "NOT_ENOUGH_INFO       0.45      1.00      0.62       220\n",
            "\n",
            "       accuracy                           0.45       491\n",
            "      macro avg       0.15      0.33      0.21       491\n",
            "   weighted avg       0.20      0.45      0.28       491\n",
            "\n",
            "Epoch 2/10 - Training Loss: 1.0041954214756306\n",
            "Epoch 2/10 - Validation Loss: 1.0712772607803345\n",
            "Accuracy: 0.4684317718940937\n",
            "F1 Score: 0.2776992905182058\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.37      0.08      0.13        92\n",
            "       SUPPORTS       0.78      0.04      0.07       179\n",
            "NOT_ENOUGH_INFO       0.47      0.98      0.63       220\n",
            "\n",
            "       accuracy                           0.47       491\n",
            "      macro avg       0.54      0.37      0.28       491\n",
            "   weighted avg       0.56      0.47      0.33       491\n",
            "\n",
            "Epoch 3/10 - Training Loss: 0.9650418960131132\n",
            "Epoch 3/10 - Validation Loss: 1.0807566940784454\n",
            "Accuracy: 0.4969450101832994\n",
            "F1 Score: 0.35964851971108497\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.36      0.17      0.23        92\n",
            "       SUPPORTS       0.69      0.11      0.19       179\n",
            "NOT_ENOUGH_INFO       0.50      0.95      0.65       220\n",
            "\n",
            "       accuracy                           0.50       491\n",
            "      macro avg       0.51      0.41      0.36       491\n",
            "   weighted avg       0.54      0.50      0.41       491\n",
            "\n",
            "Epoch 4/10 - Training Loss: 0.9270757528451773\n",
            "Epoch 4/10 - Validation Loss: 1.1058337986469269\n",
            "Accuracy: 0.4908350305498982\n",
            "F1 Score: 0.3800572388599113\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.32      0.21      0.25        92\n",
            "       SUPPORTS       0.60      0.16      0.25       179\n",
            "NOT_ENOUGH_INFO       0.51      0.88      0.64       220\n",
            "\n",
            "       accuracy                           0.49       491\n",
            "      macro avg       0.47      0.41      0.38       491\n",
            "   weighted avg       0.50      0.49      0.43       491\n",
            "\n",
            "Epoch 5/10 - Training Loss: 0.8908180594444275\n",
            "Epoch 5/10 - Validation Loss: 1.1723564118146896\n",
            "Accuracy: 0.5234215885947047\n",
            "F1 Score: 0.4136745826668307\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.37      0.17      0.24        92\n",
            "       SUPPORTS       0.64      0.23      0.34       179\n",
            "NOT_ENOUGH_INFO       0.52      0.90      0.66       220\n",
            "\n",
            "       accuracy                           0.52       491\n",
            "      macro avg       0.51      0.44      0.41       491\n",
            "   weighted avg       0.54      0.52      0.47       491\n",
            "\n",
            "Epoch 6/10 - Training Loss: 0.8606963368562551\n",
            "Epoch 6/10 - Validation Loss: 1.1086081862449646\n",
            "Accuracy: 0.5112016293279023\n",
            "F1 Score: 0.439826696249533\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.22      0.21      0.21        92\n",
            "       SUPPORTS       0.63      0.37      0.47       179\n",
            "NOT_ENOUGH_INFO       0.55      0.75      0.63       220\n",
            "\n",
            "       accuracy                           0.51       491\n",
            "      macro avg       0.47      0.44      0.44       491\n",
            "   weighted avg       0.52      0.51      0.50       491\n",
            "\n",
            "Epoch 7/10 - Training Loss: 0.8283493152031531\n",
            "Epoch 7/10 - Validation Loss: 1.163490816950798\n",
            "Accuracy: 0.5519348268839104\n",
            "F1 Score: 0.463324678009017\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.33      0.17      0.23        92\n",
            "       SUPPORTS       0.65      0.41      0.50       179\n",
            "NOT_ENOUGH_INFO       0.55      0.83      0.66       220\n",
            "\n",
            "       accuracy                           0.55       491\n",
            "      macro avg       0.51      0.47      0.46       491\n",
            "   weighted avg       0.54      0.55      0.52       491\n",
            "\n",
            "Epoch 8/10 - Training Loss: 0.8162775213901813\n",
            "Epoch 8/10 - Validation Loss: 1.1745951473712921\n",
            "Accuracy: 0.5234215885947047\n",
            "F1 Score: 0.45200350050725374\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.26      0.22      0.24        92\n",
            "       SUPPORTS       0.67      0.38      0.48       179\n",
            "NOT_ENOUGH_INFO       0.54      0.77      0.64       220\n",
            "\n",
            "       accuracy                           0.52       491\n",
            "      macro avg       0.49      0.46      0.45       491\n",
            "   weighted avg       0.53      0.52      0.51       491\n",
            "\n",
            "Epoch 9/10 - Training Loss: 0.802343081510984\n",
            "Epoch 9/10 - Validation Loss: 1.2372797280550003\n",
            "Accuracy: 0.5356415478615071\n",
            "F1 Score: 0.44517457178755454\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.30      0.17      0.22        92\n",
            "       SUPPORTS       0.65      0.36      0.46       179\n",
            "NOT_ENOUGH_INFO       0.54      0.83      0.66       220\n",
            "\n",
            "       accuracy                           0.54       491\n",
            "      macro avg       0.49      0.45      0.45       491\n",
            "   weighted avg       0.53      0.54      0.50       491\n",
            "\n",
            "Epoch 10/10 - Training Loss: 0.7808502784142127\n",
            "Epoch 10/10 - Validation Loss: 1.1521019637584686\n",
            "Accuracy: 0.5132382892057027\n",
            "F1 Score: 0.4691962803907317\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.24      0.28      0.26        92\n",
            "       SUPPORTS       0.60      0.50      0.55       179\n",
            "NOT_ENOUGH_INFO       0.59      0.62      0.60       220\n",
            "\n",
            "       accuracy                           0.51       491\n",
            "      macro avg       0.47      0.47      0.47       491\n",
            "   weighted avg       0.53      0.51      0.52       491\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Training"
      ],
      "metadata": {
        "id": "n5guUfAH2t06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_model = ClaimVerificationTransformer(emb_size=300, vocab_size=len(vocab), num_classes =3, num_heads=6, ff_hidden_size=1024, num_encoder_layers=6,dropout=0.7, pad_idx=vocab[\"<pad>\"])\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "optimizer = torch.optim.Adam(transformer_model.parameters(), lr=0.0001)\n",
        "\n",
        "train_model(transformer_model, train_loader, dev_loader, criterion, optimizer, device=device, num_epochs=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Jm0lX_m8Vp_",
        "outputId": "9f16a5cd-543d-4f7e-ab2e-6bbf2b397926"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15 - Training Loss: 1.1000692028265733\n",
            "Epoch 1/15 - Validation Loss: 1.1579849421977997\n",
            "Accuracy: 0.19959266802443992\n",
            "F1 Score: 0.15561503746600477\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.18      0.86      0.30        92\n",
            "       SUPPORTS       0.53      0.05      0.09       179\n",
            "NOT_ENOUGH_INFO       0.32      0.05      0.08       220\n",
            "\n",
            "       accuracy                           0.20       491\n",
            "      macro avg       0.34      0.32      0.16       491\n",
            "   weighted avg       0.37      0.20      0.12       491\n",
            "\n",
            "Epoch 2/15 - Training Loss: 1.0641530339534466\n",
            "Epoch 2/15 - Validation Loss: 1.155857801437378\n",
            "Accuracy: 0.23014256619144602\n",
            "F1 Score: 0.1888466834772967\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.18      0.74      0.29        92\n",
            "       SUPPORTS       1.00      0.01      0.01       179\n",
            "NOT_ENOUGH_INFO       0.41      0.20      0.27       220\n",
            "\n",
            "       accuracy                           0.23       491\n",
            "      macro avg       0.53      0.31      0.19       491\n",
            "   weighted avg       0.58      0.23      0.18       491\n",
            "\n",
            "Epoch 3/15 - Training Loss: 1.0808176379937393\n",
            "Epoch 3/15 - Validation Loss: 1.1770113408565521\n",
            "Accuracy: 0.48879837067209775\n",
            "F1 Score: 0.2958143685854529\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.00      0.00      0.00        92\n",
            "       SUPPORTS       0.61      0.16      0.25       179\n",
            "NOT_ENOUGH_INFO       0.48      0.96      0.64       220\n",
            "\n",
            "       accuracy                           0.49       491\n",
            "      macro avg       0.36      0.37      0.30       491\n",
            "   weighted avg       0.44      0.49      0.38       491\n",
            "\n",
            "Epoch 4/15 - Training Loss: 1.0550944768465482\n",
            "Epoch 4/15 - Validation Loss: 1.1199072897434235\n",
            "Accuracy: 0.28716904276985744\n",
            "F1 Score: 0.27166737795870133\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.17      0.61      0.27        92\n",
            "       SUPPORTS       0.86      0.10      0.18       179\n",
            "NOT_ENOUGH_INFO       0.46      0.30      0.37       220\n",
            "\n",
            "       accuracy                           0.29       491\n",
            "      macro avg       0.50      0.34      0.27       491\n",
            "   weighted avg       0.55      0.29      0.28       491\n",
            "\n",
            "Epoch 5/15 - Training Loss: 1.0491420168143053\n",
            "Epoch 5/15 - Validation Loss: 1.2393480837345123\n",
            "Accuracy: 0.2668024439918534\n",
            "F1 Score: 0.26109682456364763\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.18      0.75      0.30        92\n",
            "       SUPPORTS       0.58      0.19      0.29       179\n",
            "NOT_ENOUGH_INFO       0.48      0.13      0.20       220\n",
            "\n",
            "       accuracy                           0.27       491\n",
            "      macro avg       0.41      0.36      0.26       491\n",
            "   weighted avg       0.46      0.27      0.25       491\n",
            "\n",
            "Epoch 6/15 - Training Loss: 1.0475080425922687\n",
            "Epoch 6/15 - Validation Loss: 1.2320593893527985\n",
            "Accuracy: 0.3360488798370672\n",
            "F1 Score: 0.3171616046042936\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.19      0.47      0.27        92\n",
            "       SUPPORTS       0.44      0.53      0.48       179\n",
            "NOT_ENOUGH_INFO       0.55      0.12      0.20       220\n",
            "\n",
            "       accuracy                           0.34       491\n",
            "      macro avg       0.39      0.37      0.32       491\n",
            "   weighted avg       0.44      0.34      0.32       491\n",
            "\n",
            "Epoch 7/15 - Training Loss: 1.0626934757599464\n",
            "Epoch 7/15 - Validation Loss: 1.1128417253494263\n",
            "Accuracy: 0.45010183299389\n",
            "F1 Score: 0.29942239981010405\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.34      0.24      0.28        92\n",
            "       SUPPORTS       0.00      0.00      0.00       179\n",
            "NOT_ENOUGH_INFO       0.47      0.90      0.62       220\n",
            "\n",
            "       accuracy                           0.45       491\n",
            "      macro avg       0.27      0.38      0.30       491\n",
            "   weighted avg       0.27      0.45      0.33       491\n",
            "\n",
            "Epoch 8/15 - Training Loss: 1.0361728218885569\n",
            "Epoch 8/15 - Validation Loss: 1.2322826981544495\n",
            "Accuracy: 0.34623217922606925\n",
            "F1 Score: 0.3470451229545259\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.20      0.52      0.29        92\n",
            "       SUPPORTS       0.47      0.35      0.40       179\n",
            "NOT_ENOUGH_INFO       0.50      0.27      0.35       220\n",
            "\n",
            "       accuracy                           0.35       491\n",
            "      macro avg       0.39      0.38      0.35       491\n",
            "   weighted avg       0.43      0.35      0.36       491\n",
            "\n",
            "Epoch 9/15 - Training Loss: 1.0296656250953675\n",
            "Epoch 9/15 - Validation Loss: 1.3726579248905182\n",
            "Accuracy: 0.39307535641547864\n",
            "F1 Score: 0.29602951570103264\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.38      0.20      0.26        92\n",
            "       SUPPORTS       0.39      0.92      0.55       179\n",
            "NOT_ENOUGH_INFO       0.53      0.05      0.08       220\n",
            "\n",
            "       accuracy                           0.39       491\n",
            "      macro avg       0.43      0.39      0.30       491\n",
            "   weighted avg       0.45      0.39      0.29       491\n",
            "\n",
            "Epoch 10/15 - Training Loss: 1.0349434724220863\n",
            "Epoch 10/15 - Validation Loss: 1.2685926258563995\n",
            "Accuracy: 0.3665987780040733\n",
            "F1 Score: 0.31938395101183\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.23      0.36      0.28        92\n",
            "       SUPPORTS       0.40      0.70      0.51       179\n",
            "NOT_ENOUGH_INFO       0.58      0.10      0.16       220\n",
            "\n",
            "       accuracy                           0.37       491\n",
            "      macro avg       0.41      0.39      0.32       491\n",
            "   weighted avg       0.45      0.37      0.31       491\n",
            "\n",
            "Epoch 11/15 - Training Loss: 1.0293871494439932\n",
            "Epoch 11/15 - Validation Loss: 1.292687565088272\n",
            "Accuracy: 0.48676171079429736\n",
            "F1 Score: 0.4368931694802341\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.43      0.20      0.27        92\n",
            "       SUPPORTS       0.45      0.64      0.53       179\n",
            "NOT_ENOUGH_INFO       0.54      0.48      0.51       220\n",
            "\n",
            "       accuracy                           0.49       491\n",
            "      macro avg       0.47      0.44      0.44       491\n",
            "   weighted avg       0.49      0.49      0.47       491\n",
            "\n",
            "Epoch 12/15 - Training Loss: 1.022365231697376\n",
            "Epoch 12/15 - Validation Loss: 1.2224021255970001\n",
            "Accuracy: 0.4745417515274949\n",
            "F1 Score: 0.42966227950921415\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.34      0.22      0.26        92\n",
            "       SUPPORTS       0.45      0.55      0.50       179\n",
            "NOT_ENOUGH_INFO       0.53      0.52      0.53       220\n",
            "\n",
            "       accuracy                           0.47       491\n",
            "      macro avg       0.44      0.43      0.43       491\n",
            "   weighted avg       0.47      0.47      0.47       491\n",
            "\n",
            "Epoch 13/15 - Training Loss: 1.0047866179392888\n",
            "Epoch 13/15 - Validation Loss: 1.2702169716358185\n",
            "Accuracy: 0.4725050916496945\n",
            "F1 Score: 0.44004106146963284\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.29      0.29      0.29        92\n",
            "       SUPPORTS       0.48      0.60      0.53       179\n",
            "NOT_ENOUGH_INFO       0.56      0.44      0.49       220\n",
            "\n",
            "       accuracy                           0.47       491\n",
            "      macro avg       0.44      0.45      0.44       491\n",
            "   weighted avg       0.48      0.47      0.47       491\n",
            "\n",
            "Epoch 14/15 - Training Loss: 1.0114454205219563\n",
            "Epoch 14/15 - Validation Loss: 1.2527674734592438\n",
            "Accuracy: 0.4786150712830957\n",
            "F1 Score: 0.4456264337011356\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.30      0.29      0.30        92\n",
            "       SUPPORTS       0.49      0.60      0.54       179\n",
            "NOT_ENOUGH_INFO       0.55      0.46      0.50       220\n",
            "\n",
            "       accuracy                           0.48       491\n",
            "      macro avg       0.45      0.45      0.45       491\n",
            "   weighted avg       0.48      0.48      0.48       491\n",
            "\n",
            "Epoch 15/15 - Training Loss: 1.0062194952597985\n",
            "Epoch 15/15 - Validation Loss: 1.3116239607334137\n",
            "Accuracy: 0.48879837067209775\n",
            "F1 Score: 0.4447220623654539\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.30      0.24      0.27        92\n",
            "       SUPPORTS       0.49      0.60      0.54       179\n",
            "NOT_ENOUGH_INFO       0.56      0.50      0.53       220\n",
            "\n",
            "       accuracy                           0.49       491\n",
            "      macro avg       0.45      0.45      0.44       491\n",
            "   weighted avg       0.49      0.49      0.48       491\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from collections import Counter\n",
        "\n",
        "def evaluate_model(model, claims, evidence_idxs, evidences, claim_labels, vocab, pad_idx, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_evidence_predictions = []\n",
        "    all_evidence_probs = []\n",
        "\n",
        "    for claim_tokens, evidence_idx_list, true_label in zip(claims, evidence_idxs, claim_labels):\n",
        "        # Numericalize the claim tokens\n",
        "        claim_indices = text_to_indices(claim_tokens, vocab)\n",
        "        claim_indices = [vocab[\"<sos>\"]] + claim_indices + [vocab[\"<eos>\"]]\n",
        "        claim_tensor = torch.tensor(claim_indices, dtype=torch.long).unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "        evidence_tensors = []\n",
        "        for idx in evidence_idx_list:\n",
        "            evidence_tokens = evidences[idx]\n",
        "            evidence_indices = text_to_indices(evidence_tokens, vocab)\n",
        "            evidence_indices = [vocab[\"<sos>\"]] + evidence_indices + [vocab[\"<eos>\"]]\n",
        "            evidence_tensor = torch.tensor(evidence_indices, dtype=torch.long).to(device)\n",
        "            evidence_tensors.append(evidence_tensor)\n",
        "\n",
        "        # Pad evidence tensors to the same length\n",
        "        evidence_tensors_padded = pad_sequence(evidence_tensors, batch_first=True, padding_value=pad_idx).to(device)\n",
        "\n",
        "        evidence_predictions = []\n",
        "        evidence_probs = []\n",
        "        with torch.no_grad():\n",
        "            for evidence_tensor in evidence_tensors_padded:\n",
        "                evidence_tensor = evidence_tensor.unsqueeze(0)  # Add batch dimension\n",
        "                logits = model(claim_tensor, evidence_tensor)\n",
        "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "                evidence_predictions.extend(preds)\n",
        "                #prob = torch.sigmoid(logits).item()\n",
        "                #evidence_probs.append(prob)\n",
        "\n",
        "\n",
        "        aggregated_prediction = aggregate_predictions(evidence_predictions)\n",
        "        all_preds.append(aggregated_prediction)\n",
        "        all_labels.append(true_label)\n",
        "        all_evidence_predictions.append(evidence_predictions)\n",
        "        all_evidence_probs.append(evidence_probs)\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    report = classification_report(all_labels, all_preds, target_names=['REFUTES', 'SUPPORTS', 'NOT ENOUGH INFO', 'DISPUTED'], zero_division=0)\n",
        "    return accuracy, report\n",
        "\n",
        "def aggregate_predictions(evidence_predictions):\n",
        "    counter = Counter(evidence_predictions)\n",
        "    num_supports = counter[1]\n",
        "    num_refutes = counter[0]\n",
        "\n",
        "    # Handle conflicts: if both SUPPORTS and REFUTES are present\n",
        "    if num_supports > 0 and num_refutes > 0:\n",
        "        return 3  # DISPUTED if there are both SUPPORTS and REFUTES\n",
        "\n",
        "    # Determine the class if all predictions are either SUPPORTS or REFUTES (with or without NOT ENOUGH INFO)\n",
        "    if num_supports > 0 and num_refutes == 0:\n",
        "        return 1  # SUPPORTS\n",
        "\n",
        "    if num_refutes > 0 and num_supports == 0:\n",
        "        return 0  # REFUTES\n",
        "\n",
        "    # Default to NOT ENOUGH INFO if there are no SUPPORTS or REFUTES\n",
        "    return 2\n",
        "\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "gru_accuracy, gru_report = evaluate_model(gru_model, dev_claims_text_processed, dev_k_indices, evidence_text_processed, dev_claim_labels, vocab, vocab[\"<pad>\"], device)\n",
        "print(f'GRU Model Accuracy: {gru_accuracy}')\n",
        "print(f'GRU Model Classification Report:\\n {gru_report}')\n",
        "\n",
        "tran_accuracy, tran_report = evaluate_model(transformer_model, dev_claims_text_processed, dev_k_indices, evidence_text_processed, dev_claim_labels, vocab, vocab[\"<pad>\"], device)\n",
        "print(f'Transformer Model Accuracy: {tran_accuracy}')\n",
        "print(f'Transformer Model Classification Report:\\n {tran_report}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV4K6bawgyGi",
        "outputId": "7622b782-56ae-443a-fe03-eaaf6be07846"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRU Model Accuracy: 0.4090909090909091\n",
            "GRU Model Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.24      0.37      0.29        27\n",
            "       SUPPORTS       0.56      0.51      0.54        68\n",
            "NOT ENOUGH INFO       0.38      0.37      0.37        41\n",
            "       DISPUTED       0.25      0.17      0.20        18\n",
            "\n",
            "       accuracy                           0.41       154\n",
            "      macro avg       0.36      0.35      0.35       154\n",
            "   weighted avg       0.42      0.41      0.41       154\n",
            "\n",
            "Transformer Model Accuracy: 0.42207792207792205\n",
            "Transformer Model Classification Report:\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.50      0.30      0.37        27\n",
            "       SUPPORTS       0.50      0.54      0.52        68\n",
            "NOT ENOUGH INFO       0.37      0.39      0.38        41\n",
            "       DISPUTED       0.19      0.22      0.21        18\n",
            "\n",
            "       accuracy                           0.42       154\n",
            "      macro avg       0.39      0.36      0.37       154\n",
            "   weighted avg       0.43      0.42      0.42       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2024 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPitXZzTsyTn",
        "outputId": "4ae940ac-fd4f-446b-b3ec-c58b84037987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zG5AGQP0hznC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import math\n",
        "import json\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from collections import Counter, OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ohyt_MA86_7e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "evidences = pd.read_json('/content/drive/MyDrive/nlp/data/evidence.json', orient='index')\n",
        "train_claims = pd.read_json('/content/drive/MyDrive/nlp/data/train-claims.json', orient='index')\n",
        "dev_claims = pd.read_json('/content/drive/MyDrive/nlp/data/dev-claims.json', orient='index')\n",
        "\n",
        "#update column names\n",
        "evidences.reset_index(inplace=True)\n",
        "evidences.columns = ['evidence_id', 'evidence_text']\n",
        "\n",
        "train_claims.reset_index(inplace=True)\n",
        "train_claims.rename(columns={'index': 'claim_id'}, inplace=True)\n",
        "\n",
        "dev_claims.reset_index(inplace=True)\n",
        "dev_claims.rename(columns={'index': 'claim_id'}, inplace=True)\n",
        "\n",
        "evidence_id = evidences['evidence_id']\n",
        "evidence_text = evidences['evidence_text']\n",
        "evidence_idx = evidences.index.tolist()\n",
        "\n",
        "evidence_id_dict = dict(zip(evidence_id, evidence_idx))\n",
        "\n",
        "train_claims_text = train_claims['claim_text']\n",
        "train_evidence_ids = train_claims['evidences']\n",
        "train_claim_labels = train_claims['claim_label']\n",
        "#map evidence_id to their corrosponding index for faster processing\n",
        "train_evidence_idxs = train_evidence_ids.apply(lambda x: [evidence_id_dict[evidence_id] for evidence_id in x])\n",
        "\n",
        "dev_claims_text = dev_claims['claim_text']\n",
        "dev_claim_labels = dev_claims['claim_label']\n",
        "dev_evidence_ids = dev_claims['evidences']\n",
        "dev_evidence_idxs = dev_evidence_ids.apply(lambda x: [evidence_id_dict[evidence_id] for evidence_id in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEmCnO6TkYRn"
      },
      "outputs": [],
      "source": [
        "test_claims = pd.read_json('/content/drive/MyDrive/nlp/data/test-claims-unlabelled.json', orient='index')\n",
        "test_claims.reset_index(inplace=True)\n",
        "test_claims.columns = ['claim_id', 'claim_text']\n",
        "test_claims_text = test_claims['claim_text']\n",
        "test_claims_id = test_claims['claim_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YV2PK7ldyQao"
      },
      "outputs": [],
      "source": [
        "dev_claim_ids = dev_claims['claim_id']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6eWAVRHbYL_j"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "dev_evidence_indices = json.load(open(\"/content/drive/MyDrive/nlp/data/reranked_indices.json\", \"r\"))\n",
        "test_evidence_indices = json.load(open(\"/content/drive/MyDrive/nlp/data/test_reranked_indices.json\", \"r\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J12VT62YYjhd"
      },
      "outputs": [],
      "source": [
        "dev_k_indices = [sublist[:5] if len(sublist) >= 5 else sublist + [None] * (5 - len(sublist)) for sublist in dev_evidence_indices]\n",
        "test_k_indices = [sublist[:5] if len(sublist) >= 5 else sublist + [None] * (5 - len(sublist)) for sublist in test_evidence_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9hCn0g-7Ae2",
        "outputId": "96e2637e-1712-4613-f9d4-7d395cbf2dc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "tt = TweetTokenizer()\n",
        "stopwords = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_data(text):\n",
        "    # Tokenize the text\n",
        "    tokens = tt.tokenize(text.lower())\n",
        "\n",
        "    # Remove unwanted characters but keep alphanumeric, question marks, and important punctuation\n",
        "    tokens = [re.sub(f\"[^a-zA-Z0-9?]\", \"\", token) for token in tokens]\n",
        "\n",
        "    # Lemmatize tokens\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "train_claims_text_processed = train_claims_text.apply(preprocess_data)\n",
        "dev_claims_text_processed = dev_claims_text.apply(preprocess_data)\n",
        "evidence_text_processed = evidence_text.apply(preprocess_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "T_4DV847328f"
      },
      "outputs": [],
      "source": [
        "from collections import Counter, OrderedDict\n",
        "def build_vocab(texts, min_freq=3):\n",
        "    # Count all the words\n",
        "    word_freq = Counter()\n",
        "    for text in texts:\n",
        "        word_freq.update(text)\n",
        "\n",
        "    # Start vocab from special tokens\n",
        "    vocab = OrderedDict({\n",
        "        \"<pad>\": 0,\n",
        "        \"<unk>\": 1,\n",
        "        \"<sos>\": 2,\n",
        "        \"<eos>\": 3\n",
        "    })\n",
        "    index = 4  # Start indexing from 4 because 0-3 are reserved for special tokens\n",
        "    for word, freq in word_freq.items():\n",
        "        if freq >= min_freq:  # Only include words that meet the frequency threshold\n",
        "            vocab[word] = index\n",
        "            index += 1\n",
        "\n",
        "    return vocab\n",
        "\n",
        "# Build vocabulary using only evidence texts and applying the frequency threshold\n",
        "vocab = build_vocab(evidence_text_processed, min_freq=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "99CY84id6ZJN"
      },
      "outputs": [],
      "source": [
        "label_map = {\n",
        "    \"REFUTES\": 0,\n",
        "    \"SUPPORTS\": 1,\n",
        "    \"NOT_ENOUGH_INFO\": 2,\n",
        "    \"DISPUTED\": 3\n",
        "}\n",
        "train_claim_labels = train_claims['claim_label'].map(label_map)\n",
        "dev_claim_labels = dev_claims['claim_label'].map(label_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "RGcf2L9Fa_lc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "def text_to_indices(text, vocab):\n",
        "    indices = [vocab.get(word, vocab[\"<unk>\"]) for word in text]\n",
        "    return [vocab[\"<sos>\"]] + indices + [vocab[\"<eos>\"]]\n",
        "\n",
        "class ClaimEvidenceDataset(Dataset):\n",
        "    def __init__(self, claims, claim_labels, evidence_indices, evidences):\n",
        "        self.claims = claims\n",
        "        self.claim_labels = claim_labels\n",
        "        self.evidence_indices = evidence_indices\n",
        "        self.evidences = evidences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.claims)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        claim = self.claims[idx]\n",
        "        evidence_idxs = self.evidence_indices[idx]\n",
        "        evidences = [self.evidences[i] for i in evidence_idxs]\n",
        "        if self.claim_labels is not None:\n",
        "            label = self.claim_labels[idx]\n",
        "            return claim, evidences, label\n",
        "        else:\n",
        "            return claim, evidences, -1\n",
        "\n",
        "def custom_collate_fn(batch, vocab=vocab):\n",
        "    claims, evidence_lists, labels = zip(*batch)\n",
        "\n",
        "    # Convert claims to indices and pad them\n",
        "    claims_indices = [torch.tensor(text_to_indices(claim, vocab)) for claim in claims]\n",
        "    claims_padded = pad_sequence(claims_indices, batch_first=True, padding_value=vocab['<pad>'])\n",
        "\n",
        "    # Convert evidences to indices and pad them independently for each claim\n",
        "    max_evidence_length = max([len(evidence) for evidences in evidence_lists for evidence in evidences])\n",
        "    evidence_padded = []\n",
        "    for evidences in evidence_lists:\n",
        "        evidence_indices = [torch.tensor(text_to_indices(evidence, vocab)) for evidence in evidences]\n",
        "        padded_evidences = pad_sequence(evidence_indices, batch_first=True, padding_value=vocab['<pad>'])\n",
        "        # Pad each list of evidences to the maximum evidence length using F.pad\n",
        "        if padded_evidences.size(1) < max_evidence_length:\n",
        "            padded_evidences = F.pad(padded_evidences, (0, max_evidence_length - padded_evidences.size(1)), value=vocab['<pad>'])\n",
        "        evidence_padded.append(padded_evidences)\n",
        "\n",
        "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "    return claims_padded, evidence_padded, labels_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMmZlSPXoeM4"
      },
      "source": [
        "## 2.1 Bi-Directional GRU with Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ZahBwCH8BM-5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ClaimEvidenceModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx, dropout=0.1):\n",
        "        super(ClaimEvidenceModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "        self.attention = nn.Linear(hidden_dim * 2, 1, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def forward(self, claims, evidence_lists):\n",
        "        # Embed and encode claims\n",
        "        embedded_claims = self.embedding(claims)\n",
        "        claims_mask = (claims != self.pad_idx).unsqueeze(2).float()\n",
        "        embedded_claims *= claims_mask\n",
        "\n",
        "        embedded_claims = self.dropout(embedded_claims)\n",
        "        _, hidden_claims = self.gru(embedded_claims)\n",
        "        hidden_claims = torch.cat((hidden_claims[-2,:,:], hidden_claims[-1,:,:]), dim=1)\n",
        "        hidden_claims = self.dropout(hidden_claims)\n",
        "\n",
        "        batch_size = claims.size(0)\n",
        "        max_logits = torch.full((batch_size, self.fc.out_features), float('-inf'), device=claims.device)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            evidences = evidence_lists[i]\n",
        "            embedded_evidences = self.embedding(evidences)\n",
        "            evidences_mask = (evidences != self.pad_idx).unsqueeze(2).float()\n",
        "            embedded_evidences *= evidences_mask\n",
        "\n",
        "            embedded_evidences = self.dropout(embedded_evidences)\n",
        "            _, hidden_evidences = self.gru(embedded_evidences)\n",
        "            hidden_evidences = torch.cat((hidden_evidences[-2,:,:], hidden_evidences[-1,:,:]), dim=1)\n",
        "            hidden_evidences = self.dropout(hidden_evidences)\n",
        "\n",
        "            logits = self.fc(hidden_evidences)\n",
        "            attention_weights = F.softmax(self.attention(hidden_evidences), dim=0)\n",
        "            evidence_representation = torch.sum(attention_weights * logits, dim=0, keepdim=True)\n",
        "\n",
        "            max_logits[i, :] = torch.max(logits, dim=0).values\n",
        "\n",
        "        return F.log_softmax(max_logits, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Model instantiation\n",
        "model = ClaimEvidenceModel(vocab_size=len(vocab), embedding_dim=100, hidden_dim=256, output_dim=len(label_map), pad_idx=vocab['<pad>'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFFwgHBBo69T"
      },
      "source": [
        "## 2.2 Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "4kE815v_zjIB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch import Tensor\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(-torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(0)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: torch.Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:, :token_embedding.size(1), :])\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: torch.Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self, emb_size, num_heads, dim_feedforward, dropout):\n",
        "        super(TransformerEncoderLayer, self).__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(emb_size, num_heads, dropout=dropout, batch_first=True)\n",
        "        self.linear1 = nn.Linear(emb_size, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, emb_size)\n",
        "        self.norm1 = nn.LayerNorm(emb_size)\n",
        "        self.norm2 = nn.LayerNorm(emb_size)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.activation = F.relu\n",
        "\n",
        "    def forward(self, src: torch.Tensor, src_mask: torch.Tensor = None, src_key_padding_mask: torch.Tensor = None):\n",
        "        src2, _ = self.self_attn(src, src, src, attn_mask=src_mask, key_padding_mask=src_key_padding_mask)\n",
        "        src = src + self.dropout1(src2)\n",
        "        src = self.norm1(src)\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        src = self.norm2(src)\n",
        "        return src\n",
        "\n",
        "class ClaimVerificationTransformer(nn.Module):\n",
        "    def __init__(self, num_layers: int, emb_size: int, nhead: int, vocab_size: int, dim_feedforward: int, num_classes: int, dropout: float = 0.1, maxlen: int = 5000, pad_idx: int = 0):\n",
        "        super(ClaimVerificationTransformer, self).__init__()\n",
        "        self.embedding = TokenEmbedding(vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(emb_size, dropout, maxlen)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(emb_size, nhead, dim_feedforward, dropout, batch_first=True)\n",
        "        self.transformer_claim = nn.TransformerEncoder(encoder_layers, num_layers)\n",
        "        self.transformer_evidence = nn.TransformerEncoder(encoder_layers, num_layers)\n",
        "        self.fc = nn.Linear(emb_size, num_classes)\n",
        "        self.attention = nn.Linear(emb_size, 1)\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def forward(self, claims: Tensor, evidence_lists: Tensor):\n",
        "        # Embed and encode claims\n",
        "        embedded_claims = self.embedding(claims)\n",
        "        embedded_claims = self.positional_encoding(embedded_claims)\n",
        "        claims_mask = (claims == self.pad_idx)\n",
        "        claims_encoded = self.transformer_claim(embedded_claims, src_key_padding_mask=claims_mask)\n",
        "        #claims_encoded = claims_encoded.mean(dim=1)  # Average pooling\n",
        "        claims_encoded, _ = torch.max(claims_encoded, dim=1)  # Max pooling\n",
        "\n",
        "        batch_size = claims.size(0)\n",
        "        evidence_representations = []\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            evidences = evidence_lists[i]\n",
        "            embedded_evidences = self.embedding(evidences)\n",
        "            embedded_evidences = self.positional_encoding(embedded_evidences)\n",
        "            evidences_mask = (evidences == self.pad_idx)\n",
        "            evidences_encoded = self.transformer_evidence(embedded_evidences, src_key_padding_mask=evidences_mask)\n",
        "            evidences_encoded = evidences_encoded.mean(dim=1)  # Average pooling\n",
        "            #evidences_encoded, _ = torch.max(evidences_encoded, dim=1)  # Max pooling\n",
        "\n",
        "            # Attention mechanism\n",
        "            attention_weights = F.softmax(self.attention(evidences_encoded), dim=0)\n",
        "            evidence_representation = torch.sum(attention_weights * evidences_encoded, dim=0)\n",
        "            evidence_representations.append(evidence_representation)\n",
        "\n",
        "        evidence_representations = torch.stack(evidence_representations)\n",
        "        combined_representation = evidence_representations + claims_encoded\n",
        "        logits = self.fc(combined_representation)\n",
        "        return F.log_softmax(logits, dim=1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt55aguYioxT"
      },
      "source": [
        "## 2.3 Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "gTHBV9qOIKTG"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, dev_loader, criterion, optimizer, device, vocab, num_epochs=10, grad_clip=1.0):\n",
        "    model = model.to(device)\n",
        "    criterion = criterion.to(device)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for claims, evidence_lists, labels in train_loader:\n",
        "            claims = claims.to(device)\n",
        "            evidence_lists = [e.to(device) for e in evidence_lists]\n",
        "            labels = labels.to(device).long()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(claims, evidence_lists)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs} - Training Loss: {avg_train_loss}')\n",
        "\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for claims, evidence_lists, labels in dev_loader:\n",
        "                claims = claims.to(device)\n",
        "                evidence_lists = [e.to(device) for e in evidence_lists]\n",
        "                labels = labels.to(device).long()\n",
        "\n",
        "                logits = model(claims, evidence_lists)\n",
        "                val_loss = criterion(logits, labels)\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "                all_preds.extend(preds)\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(dev_loader)\n",
        "        accuracy = accuracy_score(all_labels, all_preds)\n",
        "        f1 = classification_report(all_labels, all_preds, target_names=['REFUTES', 'SUPPORTS', 'NOT ENOUGH INFO', 'DISPUTED'], zero_division=0, output_dict=True)['macro avg']['f1-score']\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs} - Validation Loss: {avg_val_loss}')\n",
        "        print(f'Accuracy: {accuracy}')\n",
        "        print(f'F1 Score: {f1}')\n",
        "        print(classification_report(all_labels, all_preds, target_names=['REFUTES', 'SUPPORTS', 'NOT ENOUGH INFO', 'DISPUTED'], zero_division=0))\n",
        "\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_label_counts = train_claim_labels.value_counts()\n",
        "# Convert label counts to a Tensor\n",
        "train_label_counts_tensor = torch.tensor(train_label_counts.sort_index().values, dtype=torch.float)\n",
        "\n",
        "# Calculate weights: inversely proportional to the class frequencies\n",
        "class_weights = 1.0 / train_label_counts_tensor\n",
        "\n",
        "# Normalize weights so that the smallest weight is 1.0\n",
        "#class_weights = class_weights / class_weights.min()\n",
        "\n",
        "# Move weights to the correct device (GPU or CPU)\n",
        "class_weights = class_weights.to(device)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRpTZqWyixrP"
      },
      "source": [
        "#### 2.3.1 Bi-GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWKJEovgivve",
        "outputId": "771921e4-878e-40c0-c968-c85f5678f40d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Training Loss: 1.38687732560294\n",
            "Epoch 1/10 - Validation Loss: 1.3888340711593627\n",
            "Accuracy: 0.15584415584415584\n",
            "F1 Score: 0.12366452991452992\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.11      0.04      0.06        27\n",
            "       SUPPORTS       0.00      0.00      0.00        68\n",
            "NOT ENOUGH INFO       0.71      0.12      0.21        41\n",
            "       DISPUTED       0.13      1.00      0.23        18\n",
            "\n",
            "       accuracy                           0.16       154\n",
            "      macro avg       0.24      0.29      0.12       154\n",
            "   weighted avg       0.22      0.16      0.09       154\n",
            "\n",
            "Epoch 2/10 - Training Loss: 1.2939297982624598\n",
            "Epoch 2/10 - Validation Loss: 1.3640209913253785\n",
            "Accuracy: 0.2532467532467532\n",
            "F1 Score: 0.23304084564860428\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.19      0.48      0.27        27\n",
            "       SUPPORTS       0.00      0.00      0.00        68\n",
            "NOT ENOUGH INFO       0.46      0.51      0.48        41\n",
            "       DISPUTED       0.13      0.28      0.18        18\n",
            "\n",
            "       accuracy                           0.25       154\n",
            "      macro avg       0.19      0.32      0.23       154\n",
            "   weighted avg       0.17      0.25      0.20       154\n",
            "\n",
            "Epoch 3/10 - Training Loss: 1.2004405873162405\n",
            "Epoch 3/10 - Validation Loss: 1.3690443754196167\n",
            "Accuracy: 0.2857142857142857\n",
            "F1 Score: 0.2559778841132938\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.13      0.26      0.17        27\n",
            "       SUPPORTS       0.55      0.09      0.15        68\n",
            "NOT ENOUGH INFO       0.39      0.66      0.49        41\n",
            "       DISPUTED       0.20      0.22      0.21        18\n",
            "\n",
            "       accuracy                           0.29       154\n",
            "      macro avg       0.32      0.31      0.26       154\n",
            "   weighted avg       0.39      0.29      0.25       154\n",
            "\n",
            "Epoch 4/10 - Training Loss: 1.1223824977874757\n",
            "Epoch 4/10 - Validation Loss: 1.4659735679626464\n",
            "Accuracy: 0.36363636363636365\n",
            "F1 Score: 0.2879303037004275\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.09      0.04      0.05        27\n",
            "       SUPPORTS       0.57      0.37      0.45        68\n",
            "NOT ENOUGH INFO       0.43      0.63      0.51        41\n",
            "       DISPUTED       0.11      0.22      0.14        18\n",
            "\n",
            "       accuracy                           0.36       154\n",
            "      macro avg       0.30      0.32      0.29       154\n",
            "   weighted avg       0.39      0.36      0.36       154\n",
            "\n",
            "Epoch 5/10 - Training Loss: 0.9787832498550415\n",
            "Epoch 5/10 - Validation Loss: 1.5083576679229735\n",
            "Accuracy: 0.36363636363636365\n",
            "F1 Score: 0.3159694750034568\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.15      0.15      0.15        27\n",
            "       SUPPORTS       0.50      0.37      0.42        68\n",
            "NOT ENOUGH INFO       0.50      0.56      0.53        41\n",
            "       DISPUTED       0.13      0.22      0.16        18\n",
            "\n",
            "       accuracy                           0.36       154\n",
            "      macro avg       0.32      0.32      0.32       154\n",
            "   weighted avg       0.39      0.36      0.37       154\n",
            "\n",
            "Epoch 6/10 - Training Loss: 0.8325077380452838\n",
            "Epoch 6/10 - Validation Loss: 1.6755345821380616\n",
            "Accuracy: 0.36363636363636365\n",
            "F1 Score: 0.32157015254917704\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.15      0.19      0.17        27\n",
            "       SUPPORTS       0.69      0.26      0.38        68\n",
            "NOT ENOUGH INFO       0.43      0.68      0.53        41\n",
            "       DISPUTED       0.17      0.28      0.21        18\n",
            "\n",
            "       accuracy                           0.36       154\n",
            "      macro avg       0.36      0.35      0.32       154\n",
            "   weighted avg       0.47      0.36      0.36       154\n",
            "\n",
            "Epoch 7/10 - Training Loss: 0.6546470131192889\n",
            "Epoch 7/10 - Validation Loss: 1.831117534637451\n",
            "Accuracy: 0.37012987012987014\n",
            "F1 Score: 0.3317007035372288\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.17      0.26      0.21        27\n",
            "       SUPPORTS       0.59      0.38      0.46        68\n",
            "NOT ENOUGH INFO       0.45      0.49      0.47        41\n",
            "       DISPUTED       0.16      0.22      0.19        18\n",
            "\n",
            "       accuracy                           0.37       154\n",
            "      macro avg       0.34      0.34      0.33       154\n",
            "   weighted avg       0.43      0.37      0.39       154\n",
            "\n",
            "Epoch 8/10 - Training Loss: 0.5536309940474374\n",
            "Epoch 8/10 - Validation Loss: 1.9532020807266235\n",
            "Accuracy: 0.3961038961038961\n",
            "F1 Score: 0.33214360688044897\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.19      0.19      0.19        27\n",
            "       SUPPORTS       0.53      0.44      0.48        68\n",
            "NOT ENOUGH INFO       0.46      0.56      0.51        41\n",
            "       DISPUTED       0.15      0.17      0.16        18\n",
            "\n",
            "       accuracy                           0.40       154\n",
            "      macro avg       0.33      0.34      0.33       154\n",
            "   weighted avg       0.40      0.40      0.40       154\n",
            "\n",
            "Epoch 9/10 - Training Loss: 0.526411406482969\n",
            "Epoch 9/10 - Validation Loss: 2.090023136138916\n",
            "Accuracy: 0.4090909090909091\n",
            "F1 Score: 0.3532877291138503\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.21      0.26      0.23        27\n",
            "       SUPPORTS       0.48      0.47      0.47        68\n",
            "NOT ENOUGH INFO       0.51      0.51      0.51        41\n",
            "       DISPUTED       0.23      0.17      0.19        18\n",
            "\n",
            "       accuracy                           0.41       154\n",
            "      macro avg       0.36      0.35      0.35       154\n",
            "   weighted avg       0.41      0.41      0.41       154\n",
            "\n",
            "Epoch 10/10 - Training Loss: 0.431359794310161\n",
            "Epoch 10/10 - Validation Loss: 2.1356231331825257\n",
            "Accuracy: 0.42207792207792205\n",
            "F1 Score: 0.3707063790504098\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.23      0.26      0.25        27\n",
            "       SUPPORTS       0.53      0.43      0.47        68\n",
            "NOT ENOUGH INFO       0.50      0.61      0.55        41\n",
            "       DISPUTED       0.21      0.22      0.22        18\n",
            "\n",
            "       accuracy                           0.42       154\n",
            "      macro avg       0.37      0.38      0.37       154\n",
            "   weighted avg       0.43      0.42      0.42       154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 128\n",
        "hidden_dim = 512\n",
        "output_dim = 4  # Four classes now\n",
        "model = ClaimEvidenceModel(vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx=0)\n",
        "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_dataset = ClaimEvidenceDataset(train_claims_text_processed, train_claim_labels, train_evidence_idxs, evidence_text_processed)\n",
        "train_loader = DataLoader(train_dataset, batch_size=36, shuffle=True, collate_fn=custom_collate_fn)\n",
        "dev_dataset = ClaimEvidenceDataset(dev_claims_text_processed, dev_claim_labels, dev_evidence_idxs, evidence_text_processed)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=36, shuffle=False, collate_fn=custom_collate_fn)\n",
        "\n",
        "train_model(model, train_loader, dev_loader, criterion, optimizer, device=device, vocab=vocab, num_epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZorWHY1m3x0",
        "outputId": "42c32c02-f1f3-40e3-cf01-318adb777590"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Training Loss: 1.3470669439860752\n",
            "Epoch 1/10 - Validation Loss: 1.2572819948196412\n",
            "Accuracy: 0.45454545454545453\n",
            "F1 Score: 0.1778012684989429\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.00      0.00      0.00        27\n",
            "       SUPPORTS       0.45      1.00      0.62        68\n",
            "NOT ENOUGH INFO       1.00      0.05      0.09        41\n",
            "       DISPUTED       0.00      0.00      0.00        18\n",
            "\n",
            "       accuracy                           0.45       154\n",
            "      macro avg       0.36      0.26      0.18       154\n",
            "   weighted avg       0.46      0.45      0.30       154\n",
            "\n",
            "Epoch 2/10 - Training Loss: 1.2543191977909633\n",
            "Epoch 2/10 - Validation Loss: 1.2629724502563477\n",
            "Accuracy: 0.45454545454545453\n",
            "F1 Score: 0.17940930037704234\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.00      0.00      0.00        27\n",
            "       SUPPORTS       0.46      1.00      0.63        68\n",
            "NOT ENOUGH INFO       0.67      0.05      0.09        41\n",
            "       DISPUTED       0.00      0.00      0.00        18\n",
            "\n",
            "       accuracy                           0.45       154\n",
            "      macro avg       0.28      0.26      0.18       154\n",
            "   weighted avg       0.38      0.45      0.30       154\n",
            "\n",
            "Epoch 3/10 - Training Loss: 1.1981985432761055\n",
            "Epoch 3/10 - Validation Loss: 1.2370304822921754\n",
            "Accuracy: 0.474025974025974\n",
            "F1 Score: 0.23642533936651586\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.43      0.11      0.18        27\n",
            "       SUPPORTS       0.48      0.99      0.64        68\n",
            "NOT ENOUGH INFO       0.43      0.07      0.12        41\n",
            "       DISPUTED       0.00      0.00      0.00        18\n",
            "\n",
            "       accuracy                           0.47       154\n",
            "      macro avg       0.33      0.29      0.24       154\n",
            "   weighted avg       0.40      0.47      0.35       154\n",
            "\n",
            "Epoch 4/10 - Training Loss: 1.128117401259286\n",
            "Epoch 4/10 - Validation Loss: 1.2589731216430664\n",
            "Accuracy: 0.45454545454545453\n",
            "F1 Score: 0.18715430097272553\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.00      0.00      0.00        27\n",
            "       SUPPORTS       0.46      0.99      0.63        68\n",
            "NOT ENOUGH INFO       0.38      0.07      0.12        41\n",
            "       DISPUTED       0.00      0.00      0.00        18\n",
            "\n",
            "       accuracy                           0.45       154\n",
            "      macro avg       0.21      0.26      0.19       154\n",
            "   weighted avg       0.30      0.45      0.31       154\n",
            "\n",
            "Epoch 5/10 - Training Loss: 1.1240352732794625\n",
            "Epoch 5/10 - Validation Loss: 1.2557201862335206\n",
            "Accuracy: 0.5\n",
            "F1 Score: 0.32330586080586077\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       1.00      0.04      0.07        27\n",
            "       SUPPORTS       0.57      0.74      0.64        68\n",
            "NOT ENOUGH INFO       0.40      0.61      0.48        41\n",
            "       DISPUTED       0.50      0.06      0.10        18\n",
            "\n",
            "       accuracy                           0.50       154\n",
            "      macro avg       0.62      0.36      0.32       154\n",
            "   weighted avg       0.59      0.50      0.44       154\n",
            "\n",
            "Epoch 6/10 - Training Loss: 1.1578479255948748\n",
            "Epoch 6/10 - Validation Loss: 1.2076560258865356\n",
            "Accuracy: 0.4805194805194805\n",
            "F1 Score: 0.3138739413223527\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.31      0.19      0.23        27\n",
            "       SUPPORTS       0.51      0.81      0.63        68\n",
            "NOT ENOUGH INFO       0.47      0.34      0.39        41\n",
            "       DISPUTED       0.00      0.00      0.00        18\n",
            "\n",
            "       accuracy                           0.48       154\n",
            "      macro avg       0.32      0.33      0.31       154\n",
            "   weighted avg       0.41      0.48      0.42       154\n",
            "\n",
            "Epoch 7/10 - Training Loss: 1.0656801802771432\n",
            "Epoch 7/10 - Validation Loss: 1.2359841108322143\n",
            "Accuracy: 0.44805194805194803\n",
            "F1 Score: 0.2074065692486745\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.30      0.11      0.16        27\n",
            "       SUPPORTS       0.46      0.96      0.62        68\n",
            "NOT ENOUGH INFO       0.33      0.02      0.05        41\n",
            "       DISPUTED       0.00      0.00      0.00        18\n",
            "\n",
            "       accuracy                           0.45       154\n",
            "      macro avg       0.27      0.27      0.21       154\n",
            "   weighted avg       0.34      0.45      0.32       154\n",
            "\n",
            "Epoch 8/10 - Training Loss: 1.0730887804712568\n",
            "Epoch 8/10 - Validation Loss: 1.259050965309143\n",
            "Accuracy: 0.474025974025974\n",
            "F1 Score: 0.27577793773415454\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.43      0.11      0.18        27\n",
            "       SUPPORTS       0.47      0.94      0.63        68\n",
            "NOT ENOUGH INFO       0.83      0.12      0.21        41\n",
            "       DISPUTED       0.17      0.06      0.08        18\n",
            "\n",
            "       accuracy                           0.47       154\n",
            "      macro avg       0.48      0.31      0.28       154\n",
            "   weighted avg       0.53      0.47      0.38       154\n",
            "\n",
            "Epoch 9/10 - Training Loss: 1.0497201187270029\n",
            "Epoch 9/10 - Validation Loss: 1.21206374168396\n",
            "Accuracy: 0.4935064935064935\n",
            "F1 Score: 0.3699449740370457\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.29      0.26      0.27        27\n",
            "       SUPPORTS       0.56      0.79      0.65        68\n",
            "NOT ENOUGH INFO       0.46      0.32      0.38        41\n",
            "       DISPUTED       0.40      0.11      0.17        18\n",
            "\n",
            "       accuracy                           0.49       154\n",
            "      macro avg       0.43      0.37      0.37       154\n",
            "   weighted avg       0.47      0.49      0.46       154\n",
            "\n",
            "Epoch 10/10 - Training Loss: 1.0673065032277789\n",
            "Epoch 10/10 - Validation Loss: 1.3197352409362793\n",
            "Accuracy: 0.44805194805194803\n",
            "F1 Score: 0.25496031746031744\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        REFUTES       0.35      0.22      0.27        27\n",
            "       SUPPORTS       0.47      0.90      0.62        68\n",
            "NOT ENOUGH INFO       1.00      0.02      0.05        41\n",
            "       DISPUTED       0.17      0.06      0.08        18\n",
            "\n",
            "       accuracy                           0.45       154\n",
            "      macro avg       0.50      0.30      0.25       154\n",
            "   weighted avg       0.55      0.45      0.34       154\n",
            "\n"
          ]
        }
      ],
      "source": [
        "vocab_size = len(vocab)\n",
        "embedding_dim = 128  # Increased embedding dimension for better representation\n",
        "hidden_dim = 512  # Increased hidden dimension for better representation\n",
        "output_dim = 4  # Four classes now\n",
        "num_layers = 2  # Reduced number of transformer layers\n",
        "nhead = 4  # Number of heads in multi-head attention\n",
        "dim_feedforward = 56  # Feedforward network dimension\n",
        "dropout = 0.4  # Dropout rate\n",
        "pad_idx = vocab['<pad>']\n",
        "\n",
        "model = ClaimVerificationTransformer(num_layers, embedding_dim, nhead, vocab_size, dim_feedforward, output_dim, dropout, pad_idx=pad_idx)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "train_dataset = ClaimEvidenceDataset(train_claims_text_processed, train_claim_labels, train_evidence_idxs, evidence_text_processed)\n",
        "train_loader = DataLoader(train_dataset, batch_size=36, shuffle=True, collate_fn=custom_collate_fn)\n",
        "dev_dataset = ClaimEvidenceDataset(dev_claims_text_processed, dev_claim_labels, dev_evidence_idxs, evidence_text_processed)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=36, shuffle=False, collate_fn=custom_collate_fn)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_model(model, train_loader, dev_loader, criterion, optimizer, device=device, vocab=vocab, num_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sxQ7UcSRE2NB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "dev_dataset = ClaimEvidenceDataset(dev_claims_text_processed, dev_claim_labels, dev_evidence_idxs, evidence_text_processed)\n",
        "\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate_fn)\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for claims, evidences, labels in dev_loader:\n",
        "        claims = claims.to(device)\n",
        "        evidences = [e.to(device) for e in evidences]  # List comprehension to move each batch of evidences to GPU\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(claims, evidences)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(all_labels, all_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VcKIiwIFc6F"
      },
      "outputs": [],
      "source": [
        "evidence_idx_to_id_dict = {idx: id for id, idx in evidence_id_dict.items()}\n",
        "\n",
        "label_map_inverse = {v: k for k, v in label_map.items()}\n",
        "\n",
        "\n",
        "\n",
        "dev_label_predictions = [label_map_inverse[pred] for pred in all_preds]\n",
        "dev_converted_evidence_ids = [[evidence_idx_to_id_dict[idx] for idx in indices] for indices in dev_k_indices]\n",
        "\n",
        "results = {}\n",
        "for i, claim_id in enumerate(dev_claim_ids):\n",
        "    results[claim_id] = {\n",
        "        \"claim_text\": dev_claims_text[i],\n",
        "        \"claim_label\": dev_label_predictions[i],\n",
        "        \"evidences\": dev_converted_evidence_ids[i]\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euOKIx5myHsi"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/nlp/data/dev_predictions.json', 'w') as file:\n",
        "    json.dump(results, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QADtxafjlrKC"
      },
      "outputs": [],
      "source": [
        "test_dataset = ClaimEvidenceDataset(test_claims, None, test_k_indices, evidence_text_processed)\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, collate_fn=custom_collate_fn)\n",
        "\n",
        "model.eval()\n",
        "all_preds = []\n",
        "with torch.no_grad():\n",
        "    for claims, evidences,_ in test_loader:  # Note that labels are not loaded\n",
        "        claims = claims.to(device)\n",
        "        evidences = [e.to(device) for e in evidences]  # Ensure evidences are moved to GPU\n",
        "        outputs = model(claims, evidences)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "# `all_preds` now contains the predicted labels for your test dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYzq14Mvm1C_"
      },
      "outputs": [],
      "source": [
        "# Inverse mapping for label_map\n",
        "label_map_inverse = {v: k for k, v in label_map.items()}\n",
        "# Convert numerical predictions to label strings\n",
        "label_predictions = [label_map_inverse[pred] for pred in all_preds]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFti-ljAnlzn"
      },
      "outputs": [],
      "source": [
        "\n",
        "evidence_idx_to_id_dict = {idx: id for id, idx in evidence_id_dict.items()}\n",
        "\n",
        "converted_evidence_ids = [[evidence_idx_to_id_dict[idx] for idx in indices] for indices in test_k_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pep3wub4nunX",
        "outputId": "44c27e59-6fbf-40dc-9d60-e09a6e317c3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['evidence-55562',\n",
              " 'evidence-1032935',\n",
              " 'evidence-60163',\n",
              " 'evidence-225665',\n",
              " 'evidence-377026']"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "converted_evidence_ids[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQiprVWjn3sg"
      },
      "outputs": [],
      "source": [
        "test_claims_id\n",
        "test_claims_text\n",
        "label_predictions\n",
        "converted_evidence_ids\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fs8MJfNmu0MJ"
      },
      "outputs": [],
      "source": [
        "json.dump(label_predictions, open(\"/content/drive/MyDrive/nlp/data/test_label_predictions.json\", \"w\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgmDJsdno24Q"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "for i, claim_id in enumerate(test_claims_id):\n",
        "    results[claim_id] = {\n",
        "        \"claim_text\": test_claims_text[i],\n",
        "        \"claim_label\": label_predictions[i],\n",
        "        \"evidences\": converted_evidence_ids[i]\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNiXAD2So6dD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Convert to JSON string\n",
        "json_output = json.dumps(results, indent=4)\n",
        "print(json_output)\n",
        "\n",
        "# Save to a JSON file\n",
        "with open('/content/drive/MyDrive/nlp/data/test_predictions.json', 'w') as file:\n",
        "    json.dump(results, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

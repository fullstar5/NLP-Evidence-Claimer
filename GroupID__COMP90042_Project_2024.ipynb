{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32yCsRUo8H33"
   },
   "source": [
    "# 2024 COMP90042 Project\n",
    "*Make sure you change the file name with your group id.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCybYoGz8YWQ"
   },
   "source": [
    "# Readme\n",
    "*If there is something to be noted for the marker, please mention here.*\n",
    "\n",
    "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6po98qVA8bJD"
   },
   "source": [
    "# 1.DataSet Processing\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qvff21Hv8zjk",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim_text</th>\n",
       "      <th>claim_label</th>\n",
       "      <th>evidences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claim-1937</td>\n",
       "      <td>Not only is there no scientific evidence that ...</td>\n",
       "      <td>DISPUTED</td>\n",
       "      <td>[evidence-442946, evidence-1194317, evidence-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claim-126</td>\n",
       "      <td>El Niño drove record highs in global temperatu...</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>[evidence-338219, evidence-1127398]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claim-2510</td>\n",
       "      <td>In 1946, PDO switched to a cool phase.</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>[evidence-530063, evidence-984887]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claim-2021</td>\n",
       "      <td>Weather Channel co-founder John Coleman provid...</td>\n",
       "      <td>DISPUTED</td>\n",
       "      <td>[evidence-1177431, evidence-782448, evidence-5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claim-2449</td>\n",
       "      <td>\"January 2008 capped a 12 month period of glob...</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>[evidence-1010750, evidence-91661, evidence-72...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>claim-851</td>\n",
       "      <td>The last time the planet was even four degrees...</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>[evidence-226174, evidence-1049316, evidence-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>claim-2773</td>\n",
       "      <td>Tree-ring proxy reconstructions are reliable b...</td>\n",
       "      <td>DISPUTED</td>\n",
       "      <td>[evidence-974673, evidence-602109]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>claim-949</td>\n",
       "      <td>Under the most ambitious scenarios, they found...</td>\n",
       "      <td>DISPUTED</td>\n",
       "      <td>[evidence-707654, evidence-28478, evidence-491...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>claim-1019</td>\n",
       "      <td>An additional kick was supplied by an El Niño ...</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>[evidence-863309, evidence-61462, evidence-639...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>claim-2834</td>\n",
       "      <td>When stomata-derived CO2 (red) is compared to ...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>[evidence-439640]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     claim_id                                         claim_text  \\\n",
       "0  claim-1937  Not only is there no scientific evidence that ...   \n",
       "1   claim-126  El Niño drove record highs in global temperatu...   \n",
       "2  claim-2510             In 1946, PDO switched to a cool phase.   \n",
       "3  claim-2021  Weather Channel co-founder John Coleman provid...   \n",
       "4  claim-2449  \"January 2008 capped a 12 month period of glob...   \n",
       "5   claim-851  The last time the planet was even four degrees...   \n",
       "6  claim-2773  Tree-ring proxy reconstructions are reliable b...   \n",
       "7   claim-949  Under the most ambitious scenarios, they found...   \n",
       "8  claim-1019  An additional kick was supplied by an El Niño ...   \n",
       "9  claim-2834  When stomata-derived CO2 (red) is compared to ...   \n",
       "\n",
       "       claim_label                                          evidences  \n",
       "0         DISPUTED  [evidence-442946, evidence-1194317, evidence-1...  \n",
       "1          REFUTES                [evidence-338219, evidence-1127398]  \n",
       "2         SUPPORTS                 [evidence-530063, evidence-984887]  \n",
       "3         DISPUTED  [evidence-1177431, evidence-782448, evidence-5...  \n",
       "4  NOT_ENOUGH_INFO  [evidence-1010750, evidence-91661, evidence-72...  \n",
       "5  NOT_ENOUGH_INFO  [evidence-226174, evidence-1049316, evidence-3...  \n",
       "6         DISPUTED                 [evidence-974673, evidence-602109]  \n",
       "7         DISPUTED  [evidence-707654, evidence-28478, evidence-491...  \n",
       "8  NOT_ENOUGH_INFO  [evidence-863309, evidence-61462, evidence-639...  \n",
       "9         SUPPORTS                                  [evidence-439640]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "evidence = pd.read_json('data/evidence.json', orient='index').reset_index().rename(columns={'index': 'evidence_id', 0: 'evidence_text'})\n",
    "train = pd.read_json('data/train-claims.json', orient='index').reset_index().rename(columns={'index': 'claim_id'})\n",
    "dev = pd.read_json('data/dev-claims.json', orient='index')\n",
    "dev_baseline = pd.read_json('data/dev-claims-baseline.json', orient='index')\n",
    "test = pd.read_json('data/test-claims-unlabelled.json', orient='index')   \n",
    "\n",
    "# train = train.explode('evidences')\n",
    "# train = pd.merge(train, evidence, on='evidences', how='left')\n",
    "train.head(10)\n",
    "#evidence.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_id</th>\n",
       "      <th>claim_text</th>\n",
       "      <th>claim_label</th>\n",
       "      <th>evidences</th>\n",
       "      <th>evidence_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>claim-1937</td>\n",
       "      <td>Not only is there no scientific evidence that ...</td>\n",
       "      <td>DISPUTED</td>\n",
       "      <td>[evidence-442946, evidence-1194317, evidence-1...</td>\n",
       "      <td>[At very high concentrations (100 times atmosp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claim-126</td>\n",
       "      <td>El Niño drove record highs in global temperatu...</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>[evidence-338219, evidence-1127398]</td>\n",
       "      <td>[While ‘climate change’ can be due to natural ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>claim-2510</td>\n",
       "      <td>In 1946, PDO switched to a cool phase.</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>[evidence-530063, evidence-984887]</td>\n",
       "      <td>[There is evidence of reversals in the prevail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>claim-2021</td>\n",
       "      <td>Weather Channel co-founder John Coleman provid...</td>\n",
       "      <td>DISPUTED</td>\n",
       "      <td>[evidence-1177431, evidence-782448, evidence-5...</td>\n",
       "      <td>[There is no convincing scientific evidence th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>claim-2449</td>\n",
       "      <td>\"January 2008 capped a 12 month period of glob...</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "      <td>[evidence-1010750, evidence-91661, evidence-72...</td>\n",
       "      <td>[With average temperature +8.1 °C (47 °F)., Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     claim_id                                         claim_text  \\\n",
       "0  claim-1937  Not only is there no scientific evidence that ...   \n",
       "1   claim-126  El Niño drove record highs in global temperatu...   \n",
       "2  claim-2510             In 1946, PDO switched to a cool phase.   \n",
       "3  claim-2021  Weather Channel co-founder John Coleman provid...   \n",
       "4  claim-2449  \"January 2008 capped a 12 month period of glob...   \n",
       "\n",
       "       claim_label                                          evidences  \\\n",
       "0         DISPUTED  [evidence-442946, evidence-1194317, evidence-1...   \n",
       "1          REFUTES                [evidence-338219, evidence-1127398]   \n",
       "2         SUPPORTS                 [evidence-530063, evidence-984887]   \n",
       "3         DISPUTED  [evidence-1177431, evidence-782448, evidence-5...   \n",
       "4  NOT_ENOUGH_INFO  [evidence-1010750, evidence-91661, evidence-72...   \n",
       "\n",
       "                                       evidence_text  \n",
       "0  [At very high concentrations (100 times atmosp...  \n",
       "1  [While ‘climate change’ can be due to natural ...  \n",
       "2  [There is evidence of reversals in the prevail...  \n",
       "3  [There is no convincing scientific evidence th...  \n",
       "4  [With average temperature +8.1 °C (47 °F)., Th...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence_dict = dict(zip(evidence['evidence_id'], evidence['evidence_text']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claim_label\n",
      "SUPPORTS           519\n",
      "NOT_ENOUGH_INFO    386\n",
      "REFUTES            199\n",
      "DISPUTED           124\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "label_distribution = train['claim_label'].value_counts()\n",
    "\n",
    "# Display the distribution\n",
    "print(label_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "#Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Stopwords set for faster membership checking\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    # Tokenize text\n",
    "    tokens = text.split()\n",
    "    # Remove stopwords and apply lemmatization\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply the function to a DataFrame column\n",
    "def preprocess_series(text_series):\n",
    "    return text_series.apply(preprocess_text)\n",
    "\n",
    "evidence['preprocessed_text'] = preprocess_series(evidence['evidence_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "tt = TweetTokenizer()\n",
    "stopwords = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_data(text):  \n",
    "    tokens = tt.tokenize(text)\n",
    "    \n",
    "    processed_tokens = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        token = token.lower()\n",
    "        if token not in stopwords and token.isalpha():\n",
    "            lemma = lemmatizer.lemmatize(token)\n",
    "            processed_tokens.append(lemma)\n",
    "    \n",
    "    return ' '.join(processed_tokens)\n",
    "\n",
    "train['processed_claim_text'] = train['claim_text'].apply(preprocess_data)\n",
    "train['processed_evidence_text'] = train['evidence_text'].apply(preprocess_data)\n",
    "evidence['preprocessed_text'] = evidence['evidence_text'].apply(preprocess_data)\n",
    "\n",
    "train_claims = train['processed_claim_text']\n",
    "train_evidences = train['processed_evidence_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming 'all_evidence' is a DataFrame containing all the evidence passages\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(evidence['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_documents(query, tfidf_matrix, vectorizer, top_k=5):\n",
    "    # Transform the query to the same TF-IDF vector space as the evidence\n",
    "    query_tfidf = vectorizer.transform([query])\n",
    "    \n",
    "    # Compute cosine similarities between the query and all documents\n",
    "    cosine_similarities = cosine_similarity(query_tfidf, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Get the top k indices of documents with the highest similarity scores\n",
    "    top_k_indices = cosine_similarities.argsort()[-top_k:][::-1]\n",
    "    \n",
    "    return top_k_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1FA2ao2l8hOg"
   },
   "source": [
    "# 2. Model Implementation\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIEqDDT78q39"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EzGuzHPE87Ya"
   },
   "source": [
    "# 3.Testing and Evaluation\n",
    "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ZVeNYIH9IaL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mefSOe8eTmGP"
   },
   "source": [
    "## Object Oriented Programming codes here\n",
    "\n",
    "*You can use multiple code snippets. Just add more if needed*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

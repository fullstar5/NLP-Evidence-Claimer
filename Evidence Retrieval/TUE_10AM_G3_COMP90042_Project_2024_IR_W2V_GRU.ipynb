{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2024 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksInulbb9Wun"
      },
      "source": [
        "## 1.1 Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rgvgk9W9Wun",
        "outputId": "8a78c472-e40a-44d5-d0f0-76953a702735"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import random\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvff21Hv8zjk",
        "outputId": "b819173f-a74d-4741-bedd-e03a30ff4327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "evidences = pd.read_json('/content/drive/MyDrive/nlp/data/evidence.json', orient='index')\n",
        "train_claims = pd.read_json('/content/drive/MyDrive/nlp/data/train-claims.json', orient='index')\n",
        "dev_claims = pd.read_json('/content/drive/MyDrive/nlp/data/dev-claims.json', orient='index')\n",
        "\n",
        "#update column names\n",
        "evidences.reset_index(inplace=True)\n",
        "evidences.columns = ['evidence_id', 'evidence_text']\n",
        "\n",
        "train_claims.reset_index(inplace=True)\n",
        "train_claims.rename(columns={'index': 'claim_id'}, inplace=True)\n",
        "\n",
        "dev_claims.reset_index(inplace=True)\n",
        "dev_claims.rename(columns={'index': 'claim_id'}, inplace=True)\n",
        "\n",
        "evidence_id = evidences['evidence_id']\n",
        "evidence_text = evidences['evidence_text']\n",
        "evidence_idx = evidences.index.tolist()\n",
        "\n",
        "evidence_id_dict = dict(zip(evidence_id, evidence_idx))\n",
        "\n",
        "train_claims_text = train_claims['claim_text']\n",
        "train_evidence_ids = train_claims['evidences']\n",
        "#map evidence_id to their corrosponding index for faster processing\n",
        "train_evidence_idxs = train_evidence_ids.apply(lambda x: [evidence_id_dict[evidence_id] for evidence_id in x])\n",
        "\n",
        "dev_claims_text = dev_claims['claim_text']\n",
        "dev_evidence_ids = dev_claims['evidences']\n",
        "dev_evidence_idxs = dev_evidence_ids.apply(lambda x: [evidence_id_dict[evidence_id] for evidence_id in x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IrTnFcd9Wuo"
      },
      "source": [
        "## 1.2 Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "82z9DJ119Wup"
      },
      "outputs": [],
      "source": [
        "#text preprocessing\n",
        "tt = TweetTokenizer()\n",
        "stopwords = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_data(text):\n",
        "    tokens = tt.tokenize(text)\n",
        "\n",
        "    processed_tokens = []\n",
        "\n",
        "    for token in tokens:\n",
        "        token = token.lower()\n",
        "        if token not in stopwords and token.isalpha():\n",
        "            stemmed_token = stemmer.stem(token)\n",
        "            processed_tokens.append(stemmed_token)\n",
        "\n",
        "    return processed_tokens\n",
        "\n",
        "train_claims_text_processed = train_claims_text.apply(preprocess_data)\n",
        "dev_claims_text_precessed = dev_claims_text.apply(preprocess_data)\n",
        "evidence_text_processed = evidence_text.apply(preprocess_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Aw0txwt9Wup"
      },
      "source": [
        "## 1.3 Word2Vec Embeddings (For Negative sampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rHLO51oC9Wup"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Train Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=evidence_text_processed, vector_size=300, window=10, min_count=3, workers=12, sg=1, hs=0)\n",
        "\n",
        "def generate_embedding(text, model):\n",
        "    # Filter out words that are not in the Word2Vec model's vocabulary\n",
        "    words = [word for word in text if word in model.wv.key_to_index]\n",
        "    if not words:  # Handle cases where none of the words are in the vocabulary\n",
        "        return np.zeros(model.vector_size)\n",
        "    # Get embeddings for each word in the text and average them\n",
        "    word_embeddings = [model.wv[word] for word in words]\n",
        "    sentence_embedding = np.mean(word_embeddings, axis=0)\n",
        "    return sentence_embedding\n",
        "\n",
        "# Generate embeddings for train claim_text\n",
        "train_claim_text_embeddings = [generate_embedding(text, word2vec_model) for text in train_claims_text_processed]\n",
        "\n",
        "# Generate embeddings for dev claim_text\n",
        "dev_claim_text_embeddings = [generate_embedding(text, word2vec_model) for text in dev_claims_text_precessed]\n",
        "\n",
        "# Generate embeddings for all evidence texts\n",
        "evidence_embeddings = [generate_embedding(text, word2vec_model) for text in evidence_text_processed]\n",
        "\n",
        "# Function to compute cosine similarity scores for all claims and evidence embeddings\n",
        "def compute_similarity_scores(claim_embeddings, evidence_embeddings):\n",
        "    similarity_scores = cosine_similarity(claim_embeddings, evidence_embeddings)\n",
        "    return similarity_scores\n",
        "\n",
        "\n",
        "# Compute cosine similarity scores for training claims and evidence embeddings\n",
        "train_similarity_scores = compute_similarity_scores(train_claim_text_embeddings, evidence_embeddings)\n",
        "\n",
        "# Compute cosine similarity scores for development claims and evidence embeddings\n",
        "dev_similarity_scores = compute_similarity_scores(dev_claim_text_embeddings, evidence_embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJNfW9SJ9Wup",
        "outputId": "e784ef1a-65f7-439b-f05c-d54eb94e7e8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Recall at K: 0.1896986970684039\n",
            "Dev Recall at K: 0.19036796536796524\n"
          ]
        }
      ],
      "source": [
        "#Evaluate the word2vec recall rate at different k values\n",
        "def compute_recall_at_k(similarity_scores, true_indices, k):\n",
        "    recall_values = []\n",
        "\n",
        "    # Convert similarity scores to PyTorch tensor\n",
        "    similarity_scores_tensor = torch.FloatTensor(similarity_scores)\n",
        "\n",
        "    # Get top k indices for each sample\n",
        "    top_k_indices = torch.topk(similarity_scores_tensor, k, dim=-1).indices.tolist()\n",
        "\n",
        "    for i in range(len(true_indices)):\n",
        "\n",
        "        true_indices_i = true_indices[i]\n",
        "\n",
        "        recall_count = sum(1 for idx in true_indices_i if idx in top_k_indices[i])\n",
        "\n",
        "        recall = recall_count / len(true_indices_i)\n",
        "\n",
        "        recall_values.append(recall)\n",
        "\n",
        "    # Compute average recall over all samples\n",
        "    avg_recall = sum(recall_values) / len(recall_values)\n",
        "\n",
        "    return avg_recall\n",
        "\n",
        "\n",
        "train_recall_at_k = compute_recall_at_k(train_similarity_scores, train_evidence_idxs, 15)\n",
        "print(\"Training Recall at K:\", train_recall_at_k)\n",
        "\n",
        "dev_recall_at_k = compute_recall_at_k(dev_similarity_scores, dev_evidence_idxs, 10)\n",
        "print(\"Dev Recall at K:\", dev_recall_at_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HRNKezPQ9Wup"
      },
      "outputs": [],
      "source": [
        "def get_top_k_indices(similarity_scores, k=1000):\n",
        "    if isinstance(similarity_scores, np.ndarray):\n",
        "        similarity_scores_tensor = torch.FloatTensor(similarity_scores)\n",
        "    else:\n",
        "        similarity_scores_tensor = similarity_scores\n",
        "\n",
        "    # Get top k indices for each sample using PyTorch\n",
        "    top_k_values, top_k_indices = torch.topk(similarity_scores_tensor, k, dim=1, largest=True, sorted=True)\n",
        "\n",
        "    # Convert tensor indices to numpy arrays\n",
        "    top_k_indices_np = top_k_indices.cpu().numpy()\n",
        "    top_k_values_np = top_k_values.cpu().numpy()\n",
        "\n",
        "    # Optionally convert numpy arrays to lists if needed\n",
        "    top_k_indices_list = top_k_indices_np.tolist()\n",
        "    top_k_values_list = top_k_values_np.tolist()\n",
        "\n",
        "    return top_k_indices_list, top_k_values_list\n",
        "\n",
        "train_top_indices, _ = get_top_k_indices(train_similarity_scores, k=50)\n",
        "dev_top_indices, dev_orig_scores = get_top_k_indices(dev_similarity_scores, k=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiGozsx3hMON",
        "outputId": "85bfaade-e0d9-4c9a-c1ab-7df5cac3ecc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "288364"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1pk8RmbV9Wuq"
      },
      "outputs": [],
      "source": [
        "embedding_dim = word2vec_model.vector_size\n",
        "vocab = {word: idx for idx, word in enumerate(word2vec_model.wv.index_to_key)}\n",
        "\n",
        "# Calculate the current maximum index in the vocabulary\n",
        "max_index = max(vocab.values())\n",
        "\n",
        "\n",
        "# vocab['<cls>'] = max_index + 1\n",
        "# vocab['<sep>'] = max_index + 2\n",
        "vocab['<unk>'] = max_index + 1\n",
        "vocab['<pad>'] = max_index + 2\n",
        "\n",
        "\n",
        "# Create random embeddings for the three new special tokens\n",
        "random_embeddings = np.zeros((1, embedding_dim))\n",
        "\n",
        "# Extend the embedding matrix with random embeddings for special tokens\n",
        "padding_embeddings = np.zeros((1, embedding_dim))  # Typically zero vector for padding\n",
        "\n",
        "extended_embeddings = np.vstack([\n",
        "    word2vec_model.wv.vectors,  # Existing embeddings from Word2Vec\n",
        "    random_embeddings,\n",
        "    padding_embeddings\n",
        "])\n",
        "embedding_matrix = torch.FloatTensor(extended_embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcWMPVTU9Wuq"
      },
      "source": [
        "## 1.4 Dataset Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG9sPShme3Na"
      },
      "source": [
        "### 1.4.1 Random Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ru_9UMnr9Wuq"
      },
      "outputs": [],
      "source": [
        "def text_to_indices(text, vocab):\n",
        "    return [vocab.get(token, vocab['<unk>']) for token in text]\n",
        "\n",
        "class RankingDatasetRandom(Dataset):\n",
        "    def __init__(self, claims, evidences, true_indices, top_k_indices, k=100, neg_samples = 32):\n",
        "        self.claims = claims\n",
        "        self.evidences = evidences\n",
        "        self.true_indices = true_indices\n",
        "        self.top_k_indices = top_k_indices\n",
        "        self.k = k\n",
        "        self.neg_samples = neg_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.claims)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        claim = self.claims[idx]\n",
        "        true_idxs = self.true_indices[idx]\n",
        "        top_k_indices = self.top_k_indices[idx][:self.k]\n",
        "        valid_indices = [i for i in true_idxs if i in top_k_indices]\n",
        "        if not valid_indices:\n",
        "            return None\n",
        "\n",
        "        pos_idx = random.choice(valid_indices)\n",
        "        pos_evidence = self.evidences[pos_idx]\n",
        "\n",
        "        neg_indices = [ i for i in top_k_indices if i not in valid_indices]\n",
        "        neg_evidences = random.sample([self.evidences[neg_idx] for neg_idx in neg_indices], min(self.neg_samples, len(neg_indices))) # Ensure we do not exceed available negatives\n",
        "\n",
        "        return claim, pos_evidence, neg_evidences\n",
        "\n",
        "\n",
        "def random_collate_fn(batch):\n",
        "    # Remove None items that were skipped in the dataset\n",
        "    batch = [item for item in batch if item is not None]\n",
        "\n",
        "    if not batch:\n",
        "        # If all items are None, return None. This needs to be handled in the training loop.\n",
        "        return None\n",
        "\n",
        "    claims, pos_evidences, neg_evidences_lists = zip(*batch)\n",
        "\n",
        "    # Convert claims and evidences to indices\n",
        "    claims_indices = [text_to_indices(claim, vocab) for claim in claims]\n",
        "    pos_indices = [text_to_indices(evidence, vocab) for evidence in pos_evidences]\n",
        "    neg_indices = [text_to_indices(neg, vocab) for sublist in neg_evidences_lists for neg in sublist]\n",
        "\n",
        "    # Pad all sequences\n",
        "    claims_padded = pad_sequence([torch.tensor(ci, dtype=torch.long) for ci in claims_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "    pos_padded = pad_sequence([torch.tensor(pi, dtype=torch.long) for pi in pos_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "    neg_padded = pad_sequence([torch.tensor(ni, dtype=torch.long) for ni in neg_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "\n",
        "    # Now that neg_padded is fully defined, you can reshape it\n",
        "    if neg_padded.numel() > 0:  # Check to make sure there are elements to avoid size mismatch\n",
        "        neg_padded = neg_padded.view(len(batch), -1, neg_padded.size(1))\n",
        "\n",
        "    return claims_padded, pos_padded, neg_padded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exsBNvCufgYZ"
      },
      "source": [
        "### 1.4.2 In-Batch Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZAd0TM9zf18z"
      },
      "outputs": [],
      "source": [
        "class RankingDatasetInBatch(Dataset):\n",
        "    def __init__(self, claims, evidences, true_indices):\n",
        "        self.claims = claims\n",
        "        self.evidences = evidences\n",
        "        self.true_indices = true_indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.claims)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pos_idx = random.choice(self.true_indices[idx])  # Randomly sample one positive evidence index\n",
        "        claim = self.claims[idx]\n",
        "        pos_evidence = self.evidences[pos_idx]\n",
        "        return claim, pos_evidence\n",
        "\n",
        "def inbatch_collate_fn(batch):\n",
        "    claims, pos_evidences = zip(*batch)\n",
        "\n",
        "    # Prepare claims and positive evidences\n",
        "    claims_indices = [text_to_indices(claim, vocab) for claim in claims]\n",
        "    pos_indices = [text_to_indices(evidence, vocab) for evidence in pos_evidences]\n",
        "\n",
        "    # Pad sequences for claims and positive evidences\n",
        "    claims_padded = pad_sequence([torch.tensor(ci, dtype=torch.long) for ci in claims_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "    pos_padded = pad_sequence([torch.tensor(pi, dtype=torch.long) for pi in pos_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "\n",
        "    # Generate in-batch negatives: Each claim gets the positive samples of all other claims as its negatives.\n",
        "    neg_padded_list = []\n",
        "    max_length = max([len(pi) for pi in pos_indices])  # Find the maximum length of positive evidences in the batch\n",
        "\n",
        "    for i in range(len(batch)):\n",
        "        neg_samples = [pos_indices[j] for j in range(len(batch)) if i != j]\n",
        "\n",
        "        # Pad each negative sample to the maximum length\n",
        "        neg_padded = [F.pad(torch.tensor(ni, dtype=torch.long), (0, max_length - len(ni)), value=vocab['<pad>']) for ni in neg_samples]\n",
        "        neg_padded_stack = torch.stack(neg_padded, dim=0)\n",
        "        neg_padded_list.append(neg_padded_stack)\n",
        "\n",
        "    # Stack the list of negative batches to form a single tensor\n",
        "    neg_padded_stack = torch.stack(neg_padded_list, dim=0)\n",
        "\n",
        "    return claims_padded, pos_padded, neg_padded_stack\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp3pFas7fl38"
      },
      "source": [
        "### 1.4.3 In-Batch + Top Negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "95zAO4lBf2iP"
      },
      "outputs": [],
      "source": [
        "class RankingDatasetInBatchGold(Dataset):\n",
        "    def __init__(self, claims, evidences, true_indices, top_indices):\n",
        "        self.claims = claims\n",
        "        self.evidences = evidences\n",
        "        self.true_indices = true_indices\n",
        "        self.top_indices = top_indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.claims)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pos_idx = random.choice(self.true_indices[idx])  # Randomly sample one positive evidence index\n",
        "        claim = self.claims[idx]\n",
        "        pos_evidence = self.evidences[pos_idx]\n",
        "\n",
        "        # Sample a negative from the top indices\n",
        "        top_neg_indices = [i for i in self.top_indices[idx] if i not in self.true_indices[idx]]\n",
        "        neg_idx = random.choice(top_neg_indices[:20])  # Choose one from the top 20 indices that are not true indices\n",
        "        neg_evidence = self.evidences[neg_idx]\n",
        "\n",
        "        return claim, pos_evidence, neg_evidence\n",
        "\n",
        "def inbatch_gold_collate_fn(batch):\n",
        "    claims, pos_evidences, neg_evidences = zip(*batch)\n",
        "\n",
        "    # Prepare claims, positive evidences, and sampled negative evidences\n",
        "    claims_indices = [text_to_indices(claim, vocab) for claim in claims]\n",
        "    pos_indices = [text_to_indices(evidence, vocab) for evidence in pos_evidences]\n",
        "    neg_indices = [text_to_indices(evidence, vocab) for evidence in neg_evidences]\n",
        "\n",
        "    # Pad sequences for claims, positive evidences, and sampled negative evidences\n",
        "    claims_padded = pad_sequence([torch.tensor(ci, dtype=torch.long) for ci in claims_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "    pos_padded = pad_sequence([torch.tensor(pi, dtype=torch.long) for pi in pos_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "    neg_padded = pad_sequence([torch.tensor(ni, dtype=torch.long) for ni in neg_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "\n",
        "    # Generate in-batch negatives: Each claim gets the positive samples of all other claims as its negatives.\n",
        "    neg_padded_list = []\n",
        "    for i in range(len(batch)):\n",
        "        neg_samples = [pos_indices[j] for j in range(len(batch)) if i != j]\n",
        "        neg_samples.append(neg_indices[i])  # Add the sampled negative evidence for this claim\n",
        "        neg_padded_stack = pad_sequence([torch.tensor(ni, dtype=torch.long) for ni in neg_samples], batch_first=True, padding_value=vocab['<pad>'])\n",
        "        neg_padded_list.append(neg_padded_stack)\n",
        "\n",
        "    # Find the maximum length of the negative sequences in the neg_padded_list\n",
        "    max_length = max([neg.size(1) for neg in neg_padded_list])\n",
        "\n",
        "    # Pad each sequence in the neg_padded_list to the maximum length\n",
        "    neg_padded_list = [F.pad(neg, (0, max_length - neg.size(1)), value=vocab['<pad>']) for neg in neg_padded_list]\n",
        "\n",
        "    # Stack the list of negative batches to form a single tensor\n",
        "    combined_neg_padded_stack = torch.stack(neg_padded_list, dim=0)\n",
        "\n",
        "    return claims_padded, pos_padded, combined_neg_padded_stack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55wRdIAo9Wuq"
      },
      "source": [
        "## 2.1 GRU (SiameseNetwork)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QIEqDDT78q39"
      },
      "outputs": [],
      "source": [
        "class GRU_SiameseNetwork(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_dim, use_cosine=False):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        self.gru = nn.GRU(embedding_matrix.size(1), hidden_dim, batch_first=True)\n",
        "        self.use_cosine = use_cosine\n",
        "\n",
        "    def forward(self, claim, evidence):\n",
        "        # Embed and process claim\n",
        "        claim_emb = self.embedding(claim)\n",
        "        _, claim_hidden = self.gru(claim_emb)\n",
        "        claim_hidden = claim_hidden.squeeze(0)  # Ensure shape is [batch_size, hidden_dim]\n",
        "\n",
        "        # Embed and process evidence\n",
        "        evidence_emb = self.embedding(evidence)\n",
        "        _, evidence_hidden = self.gru(evidence_emb)\n",
        "        evidence_hidden = evidence_hidden.squeeze(0)  # Ensure shape is [batch_size, hidden_dim]\n",
        "\n",
        "        if self.use_cosine:\n",
        "            # Calculate cosine similarity\n",
        "            scores_cosine = F.cosine_similarity(claim_hidden, evidence_hidden)\n",
        "            return scores_cosine\n",
        "        else:\n",
        "            # Calculate dot product\n",
        "            scores_dot = torch.bmm(claim_hidden.unsqueeze(1), evidence_hidden.unsqueeze(2)).squeeze()\n",
        "            return scores_dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COatKzYv9Wur"
      },
      "source": [
        "## 2.2 GRU + Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9YB6O-sb9Wur"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.attn = nn.Linear(hidden_dim, 1)  # Adjusted for unidirectional GRU\n",
        "\n",
        "    def forward(self, outputs):\n",
        "        attn_weights = torch.tanh(self.attn(outputs))\n",
        "        attn_weights = F.softmax(attn_weights, dim=1)\n",
        "        context = (attn_weights * outputs).sum(dim=1)\n",
        "        return context\n",
        "\n",
        "class GRU_Attn_SiameseNetwork(nn.Module):\n",
        "    def __init__(self, embedding_matrix, hidden_dim, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=False)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        # Single layer unidirectional GRU\n",
        "        self.gru = nn.GRU(embedding_matrix.size(1), hidden_dim, num_layers=1, batch_first=True, dropout=0)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.attention = Attention(hidden_dim)  # Adjusted for unidirectional output\n",
        "\n",
        "    def forward_one(self, text):\n",
        "        text_emb = self.embedding(text)\n",
        "        text_out, _ = self.gru(text_emb)\n",
        "        text_out = self.dropout(text_out)\n",
        "        text_context = self.attention(text_out)\n",
        "        return text_context\n",
        "\n",
        "    def forward(self, claims, evidences):\n",
        "        claim_contexts = self.forward_one(claims)\n",
        "        flattened_evidences = evidences.view(-1, evidences.size(-1))\n",
        "        evidence_contexts = self.forward_one(flattened_evidences)\n",
        "        evidence_contexts = evidence_contexts.view(claims.size(0), -1, self.hidden_dim)\n",
        "\n",
        "        # Calculate dot product\n",
        "        similarities = torch.bmm(claim_contexts.unsqueeze(1), evidence_contexts.transpose(1, 2)).squeeze(1)\n",
        "        return similarities\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7YMtrx09Wur"
      },
      "source": [
        "## 2.3 Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dHun-ZWjEf0h"
      },
      "outputs": [],
      "source": [
        "def listwise_loss(model, claims_emb, pos_evidences_emb, neg_evidences_emb):\n",
        "    pos_scores = model(claims_emb, pos_evidences_emb).unsqueeze(1)\n",
        "    neg_scores = torch.stack([model(claims_emb, neg) for neg in neg_evidences_emb.transpose(0, 1)], dim=1)\n",
        "\n",
        "    scores = torch.cat((pos_scores, neg_scores), dim=1)\n",
        "    scores = scores.squeeze(-1)\n",
        "    scores = F.log_softmax(scores, dim=1)\n",
        "\n",
        "    # Create target tensor where the index of positive examples is always 0\n",
        "    target = torch.zeros(scores.size(0), dtype=torch.long, device=scores.device)\n",
        "\n",
        "    return F.nll_loss(scores, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "uvGJka2u9Wur"
      },
      "outputs": [],
      "source": [
        "def margin_ranking_loss(model, claims, pos_evidences, neg_evidences, margin=1.5):\n",
        "    batch_size = claims.size(0)\n",
        "\n",
        "    # Get the scores for positive evidence\n",
        "    pos_scores = model(claims, pos_evidences).unsqueeze(1)\n",
        "\n",
        "    # Get the scores for negative evidence\n",
        "    neg_scores_list = [model(claims, neg_evidences[:, i, :]).unsqueeze(1) for i in range(neg_evidences.shape[1])]\n",
        "    neg_scores = torch.cat(neg_scores_list, dim=1)\n",
        "\n",
        "    # Calculate the margin ranking loss\n",
        "    target = torch.ones_like(neg_scores, device=claims.device)\n",
        "    pos_scores = pos_scores.expand_as(neg_scores)  # Expand pos_scores to match neg_scores shape\n",
        "    loss = F.margin_ranking_loss(pos_scores, neg_scores, target, margin=margin)\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK4tCUFy9Wur"
      },
      "source": [
        "## 2.4 Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "pf6eC5f-9Wur"
      },
      "outputs": [],
      "source": [
        "def topk_indices(indices, k=100):\n",
        "    return [indices[i][:min(k, len(indices[i]))] for i in range(len(indices))]\n",
        "\n",
        "def evaluate_model(model, claims, evidence_texts, dev_top_indices, top_k, vocab, pad_idx):\n",
        "    # Convert tensors to lists of indices and get the top k indices for evaluation\n",
        "    dev_top_indices = topk_indices(dev_top_indices, k=top_k)\n",
        "\n",
        "    dev_scores = []\n",
        "    for idx in range(len(claims)):\n",
        "        top_k_evidence_idxs = dev_top_indices[idx]\n",
        "        top_k_evidences = [evidence_texts[i] for i in top_k_evidence_idxs]\n",
        "        scores = score_query(model, claims[idx], top_k_evidences, vocab, pad_idx)\n",
        "        dev_scores.append(scores)\n",
        "\n",
        "    reranked_indices = []\n",
        "    for indices, scores in zip(dev_top_indices, dev_scores):\n",
        "        indexed_scores = list(zip(indices, scores))\n",
        "        sorted_by_score = sorted(indexed_scores, key=lambda x: x[1], reverse=True)\n",
        "        sorted_indices = [idx for idx, _ in sorted_by_score]\n",
        "        reranked_indices.append(sorted_indices)\n",
        "\n",
        "    return reranked_indices\n",
        "\n",
        "def train_model(model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, eval_fn, eval_data, vocab, pad_idx, topk=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"\\n\" + \"#\" * 50)  # Print separation line\n",
        "        print(f\"Starting Epoch {epoch+1}/{num_epochs}\")\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for batch in dataloader:\n",
        "            if batch is None:\n",
        "                continue\n",
        "\n",
        "            claim, pos_evidences, neg_evidences = batch\n",
        "            claim = claim.to(device)\n",
        "            pos_evidences = pos_evidences.to(device)\n",
        "            neg_evidences = neg_evidences.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model, claim, pos_evidences, neg_evidences)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_epoch_loss = epoch_loss / len(dataloader)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_epoch_loss}')\n",
        "\n",
        "        scheduler.step(avg_epoch_loss)\n",
        "        current_lr = scheduler.optimizer.param_groups[0]['lr']\n",
        "        print(f\"Current Learning Rate: {current_lr}\")\n",
        "\n",
        "        # Evaluation at the end of each epoch\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            reranked_indices = eval_fn(model, eval_data['claims'], eval_data['evidences'], eval_data['top_indices'], top_k=topk, vocab=vocab, pad_idx=pad_idx)\n",
        "            results = evaluate_evidence_retrieval(reranked_indices, eval_data['ground_truth'], k=5)\n",
        "            print(f\"Epoch {epoch+1} Evaluation - Recall: {results['average_recall']}, Precision: {results['average_precision']}, F1 Score: {results['average_fscore']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B311yWnNbaV0"
      },
      "source": [
        "### 2.4.1 GRU + Listwise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqsSm5qIoYbP"
      },
      "source": [
        "#### Random negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65Fxncv4XsZW",
        "outputId": "1a07c5ab-3229-423e-ca81-f00b3fad4229"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/5\n",
            "Epoch 1/5, Average Loss: 2.1955058680142567\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.03950216450216451, Precision: 0.02727272727272728, F1 Score: 0.02976190476190477\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/5\n",
            "Epoch 2/5, Average Loss: 1.0037813795165524\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.0818181818181818, Precision: 0.04415584415584418, F1 Score: 0.05321583178726038\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/5\n",
            "Epoch 3/5, Average Loss: 1.23356187847662\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.10508658008658006, Precision: 0.05714285714285715, F1 Score: 0.06877963306534736\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/5\n",
            "Epoch 4/5, Average Loss: 0.9071867422446592\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.112012987012987, Precision: 0.05714285714285715, F1 Score: 0.0692125334982478\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/5\n",
            "Epoch 5/5, Average Loss: 0.7457542181562117\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.09924242424242423, Precision: 0.053246753246753264, F1 Score: 0.06432694289837147\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#data loading\n",
        "dataset = RankingDatasetRandom(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=random_collate_fn)\n",
        "# dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "gru_model = GRU_SiameseNetwork(embedding_matrix, hidden_dim=256).to(device)\n",
        "\n",
        "criterion = listwise_loss\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(gru_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpDYcPwooeh8"
      },
      "source": [
        "#### In Batch Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1O80nHyoi52",
        "outputId": "508f11ad-8861-49b8-873b-5ce0af2ea07f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/5\n",
            "Epoch 1/5, Average Loss: 3.9717476673615284\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.04166666666666667, Precision: 0.02857142857142858, F1 Score: 0.0313852813852814\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/5\n",
            "Epoch 2/5, Average Loss: 3.16024518929995\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.047294372294372305, Precision: 0.03246753246753248, F1 Score: 0.035930735930735945\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/5\n",
            "Epoch 3/5, Average Loss: 2.2243050888706093\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.06482683982683983, Precision: 0.036363636363636376, F1 Score: 0.042383013811585254\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/5\n",
            "Epoch 4/5, Average Loss: 2.434563590131655\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.062987012987013, Precision: 0.03766233766233768, F1 Score: 0.04348072562358278\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/5\n",
            "Epoch 5/5, Average Loss: 1.1462320358467035\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.11287878787878786, Precision: 0.05714285714285715, F1 Score: 0.0696660482374768\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#data loading\n",
        "# dataset = RankingDatasetRandom(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=random_collate_fn)\n",
        "dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "gru_model = GRU_SiameseNetwork(embedding_matrix, hidden_dim=256).to(device)\n",
        "\n",
        "criterion = listwise_loss\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(gru_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASUtAb3iojUn"
      },
      "source": [
        "#### In Batch + Gold Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFmU3E8zoof7",
        "outputId": "0f2fd42b-4236-4ef9-94dd-af686b75f102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/10\n",
            "Epoch 1/10, Average Loss: 4.785622691496824\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.04913419913419914, Precision: 0.033766233766233784, F1 Score: 0.037280972995258725\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/10\n",
            "Epoch 2/10, Average Loss: 4.2801327992895475\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.0471861471861472, Precision: 0.029870129870129873, F1 Score: 0.034070294784580506\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/10\n",
            "Epoch 3/10, Average Loss: 3.479642996090824\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.09036796536796536, Precision: 0.048051948051948075, F1 Score: 0.057926200783343644\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/10\n",
            "Epoch 4/10, Average Loss: 1.2899046310093163\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.09545454545454544, Precision: 0.05064935064935067, F1 Score: 0.0612605648319934\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/10\n",
            "Epoch 5/10, Average Loss: 0.9387545147002792\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.055519480519480524, Precision: 0.03376623376623378, F1 Score: 0.03861574933003506\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 6/10\n",
            "Epoch 6/10, Average Loss: 3.150483044122366\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 6 Evaluation - Recall: 0.09989177489177486, Precision: 0.053246753246753264, F1 Score: 0.06417748917748918\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 7/10\n",
            "Epoch 7/10, Average Loss: 1.099585628974677\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 7 Evaluation - Recall: 0.08647186147186145, Precision: 0.05454545454545456, F1 Score: 0.0626881055452484\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 8/10\n",
            "Epoch 8/10, Average Loss: 1.2991657779514412\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 8 Evaluation - Recall: 0.11363636363636362, Precision: 0.05844155844155844, F1 Score: 0.07078437435580293\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 9/10\n",
            "Epoch 9/10, Average Loss: 1.1253632368802118\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 9 Evaluation - Recall: 0.10432900432900435, Precision: 0.055844155844155856, F1 Score: 0.06766130694702124\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 10/10\n",
            "Epoch 10/10, Average Loss: 1.2160433441975294\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 10 Evaluation - Recall: 0.10497835497835496, Precision: 0.05454545454545456, F1 Score: 0.06545042259327974\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#data loading\n",
        "# dataset = RankingDatasetRandom(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=random_collate_fn)\n",
        "# dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "dateset = RankingDatasetInBatchGold(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_gold_collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "gru_model = GRU_SiameseNetwork(embedding_matrix, hidden_dim=256).to(device)\n",
        "\n",
        "criterion = listwise_loss\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(gru_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ympctV7vbmxM"
      },
      "source": [
        "### 2.4.2 GRU + MarginRanking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKjQrBlYpmCm"
      },
      "source": [
        "#### Random Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AQl2eHebt5Y",
        "outputId": "f44219b0-d38b-4a1c-d29e-fdf5785fa0ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##############################\n",
            "Starting Epoch 1/5\n",
            "Epoch 1/5, Average Loss: 0.47602683692597425\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.04112554112554113, Precision: 0.02467532467532468, F1 Score: 0.02855081426509998\n",
            "\n",
            "##############################\n",
            "Starting Epoch 2/5\n",
            "Epoch 2/5, Average Loss: 0.2963211371291739\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.0420995670995671, Precision: 0.02597402597402598, F1 Score: 0.02970521541950114\n",
            "\n",
            "##############################\n",
            "Starting Epoch 3/5\n",
            "Epoch 3/5, Average Loss: 0.25288911521410906\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.04621212121212122, Precision: 0.02727272727272728, F1 Score: 0.03188517831374975\n",
            "\n",
            "##############################\n",
            "Starting Epoch 4/5\n",
            "Epoch 4/5, Average Loss: 0.09329307737061754\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.0764069264069264, Precision: 0.04155844155844158, F1 Score: 0.049866007008864156\n",
            "\n",
            "##############################\n",
            "Starting Epoch 5/5\n",
            "Epoch 5/5, Average Loss: 0.5401644838723139\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.059956709956709965, Precision: 0.03376623376623378, F1 Score: 0.0400381364667079\n"
          ]
        }
      ],
      "source": [
        "dataset = RankingDatasetRandom(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=random_collate_fn)\n",
        "# dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "# dateset = RankingDatasetInBatchGold(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_gold_collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "gru_model = GRU_SiameseNetwork(embedding_matrix, hidden_dim=256).to(device)\n",
        "\n",
        "criterion = margin_ranking_loss\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(gru_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rGHZujRqXMk"
      },
      "source": [
        "#### In-Batch Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Enah7CAqZv2",
        "outputId": "d0d84b49-b647-40a5-f6b4-af59098dd2b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/5\n",
            "Epoch 1/5, Average Loss: 1.2086798911197827\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.04166666666666667, Precision: 0.02857142857142858, F1 Score: 0.0313852813852814\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/5\n",
            "Epoch 2/5, Average Loss: 0.9666505486537249\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.04274891774891776, Precision: 0.02857142857142858, F1 Score: 0.031617192331478056\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/5\n",
            "Epoch 3/5, Average Loss: 0.6468074870510743\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.03625541125541126, Precision: 0.02467532467532468, F1 Score: 0.026875901875901883\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/5\n",
            "Epoch 4/5, Average Loss: 1.0438217436058972\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.04772727272727273, Precision: 0.02987012987012988, F1 Score: 0.034121830550401994\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/5\n",
            "Epoch 5/5, Average Loss: 0.8291707201263844\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.044588744588744594, Precision: 0.029870129870129884, F1 Score: 0.03309626881055453\n"
          ]
        }
      ],
      "source": [
        "# dataset = RankingDatasetRandom(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=random_collate_fn)\n",
        "dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "# dateset = RankingDatasetInBatchGold(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_gold_collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "gru_model = GRU_SiameseNetwork(embedding_matrix, hidden_dim=256).to(device)\n",
        "\n",
        "criterion = margin_ranking_loss\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(gru_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y67d0B1Nqi1B"
      },
      "source": [
        "#### In-Batch Negatives + Gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9nadmMnqiQd",
        "outputId": "f2797309-9c62-4a43-c067-b7b30c18faa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/5\n",
            "Epoch 1/5, Average Loss: 1.0463474919207585\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.03820346320346321, Precision: 0.02597402597402598, F1 Score: 0.02846320346320347\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/5\n",
            "Epoch 2/5, Average Loss: 0.8968893769077766\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.04231601731601732, Precision: 0.02727272727272728, F1 Score: 0.030643166357452085\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/5\n",
            "Epoch 3/5, Average Loss: 0.7256629971118692\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.06168831168831169, Precision: 0.03376623376623378, F1 Score: 0.03960523603380748\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/5\n",
            "Epoch 4/5, Average Loss: 0.5660642033132414\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.07110389610389613, Precision: 0.036363636363636376, F1 Score: 0.043480725623582774\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/5\n",
            "Epoch 5/5, Average Loss: 0.43021656873707587\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.07705627705627704, Precision: 0.04415584415584418, F1 Score: 0.05133992991135849\n"
          ]
        }
      ],
      "source": [
        "# dataset = RankingDatasetRandom(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=random_collate_fn)\n",
        "# dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "dateset = RankingDatasetInBatchGold(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_gold_collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "gru_model = GRU_SiameseNetwork(embedding_matrix, hidden_dim=256).to(device)\n",
        "\n",
        "criterion = margin_ranking_loss\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(gru_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcZKgPuLcLy2"
      },
      "source": [
        "### 2.4.3 GRU_ATTENTION + Listwise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQfSyZbYrBOq"
      },
      "source": [
        "#### Random Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udQTrAj5cTlk",
        "outputId": "845c0379-40e9-4ff9-be8d-99b595d658bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##############################\n",
            "Starting Epoch 1/5\n",
            "Epoch 1/5, Average Loss: 1.7771361332912095\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.04664502164502165, Precision: 0.02857142857142858, F1 Score: 0.03285920428777573\n",
            "\n",
            "##############################\n",
            "Starting Epoch 2/5\n",
            "Epoch 2/5, Average Loss: 2.9392272769645595\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.05173160173160174, Precision: 0.02727272727272728, F1 Score: 0.03289527932385076\n",
            "\n",
            "##############################\n",
            "Starting Epoch 3/5\n",
            "Epoch 3/5, Average Loss: 1.054238751872551\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.07564935064935065, Precision: 0.04155844155844158, F1 Score: 0.04934034219748506\n",
            "\n",
            "##############################\n",
            "Starting Epoch 4/5\n",
            "Epoch 4/5, Average Loss: 0.7275857265301632\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.11190476190476188, Precision: 0.05714285714285716, F1 Score: 0.07005772005772007\n",
            "\n",
            "##############################\n",
            "Starting Epoch 5/5\n",
            "Epoch 5/5, Average Loss: 0.57511498354627\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.08668831168831169, Precision: 0.04545454545454548, F1 Score: 0.05561224489795919\n"
          ]
        }
      ],
      "source": [
        "dataset = RankingDatasetRandom(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=random_collate_fn)\n",
        "# dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "# dateset = RankingDatasetInBatchGold(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_gold_collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "gru_model = GRU_Attn_SiameseNetwork(embedding_matrix, hidden_dim=256).to(device)\n",
        "\n",
        "criterion = listwise_loss\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(gru_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OFcRDGprEI8"
      },
      "source": [
        "#### In Batch Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPekmga5raIW",
        "outputId": "86317f9c-2c71-4cd2-cc52-97ec7e730353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/10\n",
            "Epoch 1/10, Average Loss: 2.8855569454339833\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.06233766233766234, Precision: 0.036363636363636376, F1 Score: 0.04272830344258917\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/10\n",
            "Epoch 2/10, Average Loss: 2.1878171395032835\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.0617965367965368, Precision: 0.033766233766233784, F1 Score: 0.03984230055658629\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/10\n",
            "Epoch 3/10, Average Loss: 1.855283335233346\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.07932900432900433, Precision: 0.04675324675324678, F1 Score: 0.05435992578849723\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/10\n",
            "Epoch 4/10, Average Loss: 1.6409508968010926\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.09989177489177489, Precision: 0.053246753246753264, F1 Score: 0.06379097093382809\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/10\n",
            "Epoch 5/10, Average Loss: 1.4771305872843816\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.10346320346320344, Precision: 0.05454545454545456, F1 Score: 0.06579055864770152\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 6/10\n",
            "Epoch 6/10, Average Loss: 1.3278094637088287\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 6 Evaluation - Recall: 0.10313852813852811, Precision: 0.05454545454545456, F1 Score: 0.06564625850340136\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 7/10\n",
            "Epoch 7/10, Average Loss: 1.181042308990772\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 7 Evaluation - Recall: 0.10357142857142855, Precision: 0.055844155844155856, F1 Score: 0.06662028447742734\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 8/10\n",
            "Epoch 8/10, Average Loss: 1.1096260394805517\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 8 Evaluation - Recall: 0.11060606060606057, Precision: 0.059740259740259746, F1 Score: 0.07154195011337869\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 9/10\n",
            "Epoch 9/10, Average Loss: 1.0007217870308802\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 9 Evaluation - Recall: 0.09686147186147184, Precision: 0.053246753246753264, F1 Score: 0.06338899196042053\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 10/10\n",
            "Epoch 10/10, Average Loss: 0.9588679411472418\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 10 Evaluation - Recall: 0.09318181818181814, Precision: 0.05064935064935068, F1 Score: 0.060559678416821285\n"
          ]
        }
      ],
      "source": [
        "# dataset = RankingDatasetRandom(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=random_collate_fn)\n",
        "dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "# dateset = RankingDatasetInBatchGold(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_gold_collate_fn)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Initialize model\n",
        "gru_model = GRU_Attn_SiameseNetwork(embedding_matrix, hidden_dim=256).to(device)\n",
        "\n",
        "criterion = listwise_loss\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(gru_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsZmn9RrrIEF"
      },
      "source": [
        "#### In Batch + Gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJ-S1a9JrkWz",
        "outputId": "8265e18e-0caf-4785-92b4-11ece0ce5d12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/5\n",
            "Epoch 1/5, Average Loss: 3.1354176631340613\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.037987012987013, Precision: 0.024675324675324677, F1 Score: 0.027525252525252532\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/5\n",
            "Epoch 2/5, Average Loss: 2.4771112769077988\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.03993506493506494, Precision: 0.024675324675324677, F1 Score: 0.028081838796124522\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/5\n",
            "Epoch 3/5, Average Loss: 2.277987898924412\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.0405844155844156, Precision: 0.027272727272727275, F1 Score: 0.030122655122655138\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/5\n",
            "Epoch 4/5, Average Loss: 1.9903023657747185\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.05281385281385282, Precision: 0.03766233766233768, F1 Score: 0.041785198928056086\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/5\n",
            "Epoch 5/5, Average Loss: 1.3685505732790215\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.08344155844155843, Precision: 0.04545454545454548, F1 Score: 0.05434961863533293\n"
          ]
        }
      ],
      "source": [
        "# dataset = RankingDatasetRandom(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=random_collate_fn)\n",
        "# dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "dateset = RankingDatasetInBatchGold(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_gold_collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "gru_model = GRU_Attn_SiameseNetwork(embedding_matrix, hidden_dim=256).to(device)\n",
        "\n",
        "criterion = listwise_loss\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.001)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(gru_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Prgrt6chcWXT"
      },
      "source": [
        "### 2.4.4 GRU_ATTENTION + MarginRanking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQIPcXRmr_A3"
      },
      "source": [
        "#### Random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IY4JPSkhcdQS",
        "outputId": "b779a9e0-984b-4f24-9981-78ed389090ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/10\n",
            "Epoch 1/10, Average Loss: 0.6597070049051231\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 1 Evaluation - Recall: 0.04134199134199135, Precision: 0.02857142857142858, F1 Score: 0.031240981240981257\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/10\n",
            "Epoch 2/10, Average Loss: 0.6697607715017139\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 2 Evaluation - Recall: 0.03841991341991343, Precision: 0.02597402597402598, F1 Score: 0.028499278499278507\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/10\n",
            "Epoch 3/10, Average Loss: 0.7035767276628087\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 3 Evaluation - Recall: 0.03841991341991343, Precision: 0.02597402597402598, F1 Score: 0.028499278499278507\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/10\n",
            "Epoch 4/10, Average Loss: 0.40746428398415446\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 4 Evaluation - Recall: 0.03755411255411256, Precision: 0.02597402597402598, F1 Score: 0.028174603174603186\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/10\n",
            "Epoch 5/10, Average Loss: 1.1510639983805446\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 5 Evaluation - Recall: 0.03625541125541126, Precision: 0.02467532467532468, F1 Score: 0.026875901875901883\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 6/10\n",
            "Epoch 6/10, Average Loss: 0.4122571223400509\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 6 Evaluation - Recall: 0.045238095238095244, Precision: 0.02857142857142858, F1 Score: 0.03235415378272522\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 7/10\n",
            "Epoch 7/10, Average Loss: 0.6544298770287498\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 7 Evaluation - Recall: 0.05551948051948054, Precision: 0.03246753246753248, F1 Score: 0.03758503401360545\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 8/10\n",
            "Epoch 8/10, Average Loss: 0.45769069750512686\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 8 Evaluation - Recall: 0.055303030303030305, Precision: 0.03376623376623377, F1 Score: 0.03922387136672852\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 9/10\n",
            "Epoch 9/10, Average Loss: 0.4362913100466801\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 9 Evaluation - Recall: 0.06699134199134198, Precision: 0.03506493506493508, F1 Score: 0.042254174397031545\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 10/10\n",
            "Epoch 10/10, Average Loss: 0.5367215713717414\n",
            "Current Learning Rate: 5e-05\n",
            "Epoch 10 Evaluation - Recall: 0.04534632034632035, Precision: 0.02857142857142858, F1 Score: 0.03259121830550402\n"
          ]
        }
      ],
      "source": [
        "dataset = RankingDatasetRandom(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=random_collate_fn)\n",
        "# dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "# dateset = RankingDatasetInBatchGold(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_gold_collate_fn)\n",
        "# Initialize model\n",
        "gru_model = GRU_Attn_SiameseNetwork(embedding_matrix, hidden_dim=512).to(device)\n",
        "\n",
        "criterion = margin_ranking_loss\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.0001)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(gru_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxvT6Q6rsEnY"
      },
      "source": [
        "#### In batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4PGQUDDsHAz",
        "outputId": "8d4ff293-c14d-40e3-8ff8-2aa21484cf28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/10\n",
            "Epoch 1/10, Average Loss: 1.111365088285544\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 1 Evaluation - Recall: 0.03787878787878788, Precision: 0.02597402597402598, F1 Score: 0.028318903318903327\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/10\n",
            "Epoch 2/10, Average Loss: 1.0481630907608912\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 2 Evaluation - Recall: 0.03658008658008659, Precision: 0.02467532467532468, F1 Score: 0.027020202020202028\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/10\n",
            "Epoch 3/10, Average Loss: 0.9053717437080848\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 3 Evaluation - Recall: 0.03398268398268399, Precision: 0.022077922077922082, F1 Score: 0.024422799422799433\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/10\n",
            "Epoch 4/10, Average Loss: 0.6300904668676548\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 4 Evaluation - Recall: 0.03647186147186148, Precision: 0.022077922077922082, F1 Score: 0.025159760874046595\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/10\n",
            "Epoch 5/10, Average Loss: 0.5124573208009585\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 5 Evaluation - Recall: 0.03863636363636364, Precision: 0.023376623376623377, F1 Score: 0.026783137497423216\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 6/10\n",
            "Epoch 6/10, Average Loss: 0.3580023247199372\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 6 Evaluation - Recall: 0.05497835497835499, Precision: 0.036363636363636376, F1 Score: 0.04165635951350238\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 7/10\n",
            "Epoch 7/10, Average Loss: 0.38884284214164394\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 7 Evaluation - Recall: 0.06774891774891775, Precision: 0.037662337662337675, F1 Score: 0.04504741290455577\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 8/10\n",
            "Epoch 8/10, Average Loss: 0.25287228451970106\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 8 Evaluation - Recall: 0.08787878787878786, Precision: 0.04545454545454548, F1 Score: 0.05512780869923728\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 9/10\n",
            "Epoch 9/10, Average Loss: 0.27308606574884975\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 9 Evaluation - Recall: 0.08917748917748916, Precision: 0.046753246753246776, F1 Score: 0.056426509997938586\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 10/10\n",
            "Epoch 10/10, Average Loss: 0.3438101585041015\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 10 Evaluation - Recall: 0.07673160173160173, Precision: 0.04415584415584417, F1 Score: 0.05227788084930944\n"
          ]
        }
      ],
      "source": [
        "# dataset = RankingDatasetRandom(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=random_collate_fn)\n",
        "dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "# dateset = RankingDatasetInBatchGold(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_gold_collate_fn)\n",
        "# Initialize model\n",
        "gru_model = GRU_Attn_SiameseNetwork(embedding_matrix, hidden_dim=512).to(device)\n",
        "\n",
        "criterion = margin_ranking_loss\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.0001)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(gru_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2N_C6PZsJ9D"
      },
      "source": [
        "#### In Batch + Gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z_KZFiRsKIz",
        "outputId": "ca951982-1396-4146-8475-4a6501a00431"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/10\n",
            "Epoch 1/10, Average Loss: 1.1877917700853102\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 1 Evaluation - Recall: 0.03787878787878789, Precision: 0.02597402597402598, F1 Score: 0.028318903318903327\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/10\n",
            "Epoch 2/10, Average Loss: 0.9802435988034958\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 2 Evaluation - Recall: 0.03625541125541126, Precision: 0.024675324675324684, F1 Score: 0.026875901875901883\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/10\n",
            "Epoch 3/10, Average Loss: 1.0351166549401405\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 3 Evaluation - Recall: 0.03268398268398269, Precision: 0.02077922077922078, F1 Score: 0.023124098124098127\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/10\n",
            "Epoch 4/10, Average Loss: 0.6907822417143064\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 4 Evaluation - Recall: 0.0326839826839827, Precision: 0.02077922077922078, F1 Score: 0.023124098124098127\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/10\n",
            "Epoch 5/10, Average Loss: 0.5294566676498224\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 5 Evaluation - Recall: 0.05259740259740261, Precision: 0.029870129870129873, F1 Score: 0.03484333127190271\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 6/10\n",
            "Epoch 6/10, Average Loss: 0.3533571510432431\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 6 Evaluation - Recall: 0.06244588744588744, Precision: 0.04025974025974028, F1 Score: 0.04600597814883531\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 7/10\n",
            "Epoch 7/10, Average Loss: 0.3601690599312767\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 7 Evaluation - Recall: 0.0484848484848485, Precision: 0.03376623376623378, F1 Score: 0.03794578437435582\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 8/10\n",
            "Epoch 8/10, Average Loss: 0.3470891138855129\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 8 Evaluation - Recall: 0.07413419913419912, Precision: 0.04025974025974028, F1 Score: 0.04800556586270873\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 9/10\n",
            "Epoch 9/10, Average Loss: 0.2905041965333602\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 9 Evaluation - Recall: 0.07846320346320346, Precision: 0.04285714285714288, F1 Score: 0.05125231910946197\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 10/10\n",
            "Epoch 10/10, Average Loss: 0.23608722214181072\n",
            "Current Learning Rate: 0.0001\n",
            "Epoch 10 Evaluation - Recall: 0.0775974025974026, Precision: 0.04155844155844158, F1 Score: 0.049896928468357055\n"
          ]
        }
      ],
      "source": [
        "# dataset = RankingDatasetRandom(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=random_collate_fn)\n",
        "# dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "dateset = RankingDatasetInBatchGold(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_gold_collate_fn)\n",
        "# Initialize model\n",
        "gru_model = GRU_Attn_SiameseNetwork(embedding_matrix, hidden_dim=512).to(device)\n",
        "\n",
        "criterion = margin_ranking_loss\n",
        "optimizer = optim.Adam(gru_model.parameters(), lr=0.0001)\n",
        "\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(gru_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6ZVeNYIH9IaL"
      },
      "outputs": [],
      "source": [
        "def score_query(model, query, evidences, vocab, pad_idx):\n",
        "    # Convert query and evidences to indices using the same function as during training\n",
        "    query_indices = text_to_indices(query, vocab)  # Query to indices\n",
        "    evidence_indices = [text_to_indices(evidence, vocab) for evidence in evidences]  # Evidences to indices\n",
        "\n",
        "    # Convert lists to tensors and pad\n",
        "    query_tensor = pad_sequence([torch.tensor(query_indices)], batch_first=True, padding_value=pad_idx)\n",
        "    evidence_tensors = pad_sequence([torch.tensor(ei) for ei in evidence_indices], batch_first=True, padding_value=pad_idx)\n",
        "\n",
        "   \n",
        "    query_tensor = query_tensor.to(device)\n",
        "    evidence_tensors = evidence_tensors.to(device)\n",
        "\n",
        "    # Set the model to evaluation mode and disable gradient computation\n",
        "    model.eval()\n",
        "    scores = []\n",
        "    with torch.no_grad():\n",
        "        # Process all evidences in one batch for efficiency\n",
        "        for i in range(evidence_tensors.shape[0]):\n",
        "            score = model(query_tensor, evidence_tensors[i].unsqueeze(0))\n",
        "            scores.append(score.item())\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "76a6ujov_Rt7"
      },
      "outputs": [],
      "source": [
        "def evaluate_evidence_retrieval(predicted_indices_list, actual_indices_list, k=5):\n",
        "    assert len(predicted_indices_list) == len(actual_indices_list), \"Both inputs must have the same length.\"\n",
        "\n",
        "    total_recall = 0.0\n",
        "    total_precision = 0.0\n",
        "    total_fscore = 0.0\n",
        "    num_claims = len(predicted_indices_list)\n",
        "\n",
        "    for predicted_indices, actual_indices in zip(predicted_indices_list, actual_indices_list):\n",
        "        # Convert tensors in predicted_indices to integers if they are not already\n",
        "        predicted_indices = [index.item() if isinstance(index, torch.Tensor) else index for index in predicted_indices]\n",
        "\n",
        "        # Retrieve the top k predictions\n",
        "        top_k_predicted = set(predicted_indices[:k])\n",
        "        actual_indices_set = set(actual_indices)\n",
        "\n",
        "        # Calculate the number of correct predictions\n",
        "        correct_predictions = len(top_k_predicted.intersection(actual_indices_set))\n",
        "\n",
        "        # Calculate metrics\n",
        "        if correct_predictions > 0:\n",
        "            recall = float(correct_predictions) / len(actual_indices_set)\n",
        "            precision = float(correct_predictions) / k\n",
        "            if (precision + recall) != 0:\n",
        "                fscore = 2 * (precision * recall) / (precision + recall)\n",
        "            else:\n",
        "                fscore = 0.0\n",
        "        else:\n",
        "            recall = 0.0\n",
        "            precision = 0.0\n",
        "            fscore = 0.0\n",
        "\n",
        "        # Accumulate the metrics to calculate averages later\n",
        "        total_recall += recall\n",
        "        total_precision += precision\n",
        "        total_fscore += fscore\n",
        "\n",
        "    # Calculate average metrics\n",
        "    average_recall = total_recall / num_claims\n",
        "    average_precision = total_precision / num_claims\n",
        "    average_fscore = total_fscore / num_claims\n",
        "\n",
        "    return {\n",
        "        \"average_recall\": average_recall,\n",
        "        \"average_precision\": average_precision,\n",
        "        \"average_fscore\": average_fscore\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

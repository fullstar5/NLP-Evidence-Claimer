{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2024 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksInulbb9Wun"
      },
      "source": [
        "## 1.1 Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rgvgk9W9Wun",
        "outputId": "9fb60cff-93d2-4da0-db19-96d80cb61d48"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import math\n",
        "import random\n",
        "from collections import defaultdict, Counter, OrderedDict\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix, diags\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvff21Hv8zjk",
        "outputId": "d28839ed-46f9-4bf6-e09f-6d7bc1b25943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "evidences = pd.read_json('/content/drive/MyDrive/nlp/data/evidence.json', orient='index')\n",
        "train_claims = pd.read_json('/content/drive/MyDrive/nlp/data/train-claims.json', orient='index')\n",
        "dev_claims = pd.read_json('/content/drive/MyDrive/nlp/data/dev-claims.json', orient='index')\n",
        "\n",
        "#update column names\n",
        "evidences.reset_index(inplace=True)\n",
        "evidences.columns = ['evidence_id', 'evidence_text']\n",
        "\n",
        "train_claims.reset_index(inplace=True)\n",
        "train_claims.rename(columns={'index': 'claim_id'}, inplace=True)\n",
        "\n",
        "dev_claims.reset_index(inplace=True)\n",
        "dev_claims.rename(columns={'index': 'claim_id'}, inplace=True)\n",
        "\n",
        "evidence_id = evidences['evidence_id']\n",
        "evidence_text = evidences['evidence_text']\n",
        "evidence_idx = evidences.index.tolist()\n",
        "\n",
        "evidence_id_dict = dict(zip(evidence_id, evidence_idx))\n",
        "\n",
        "train_claims_text = train_claims['claim_text']\n",
        "train_evidence_ids = train_claims['evidences']\n",
        "#map evidence_id to their corrosponding index for faster processing\n",
        "train_evidence_idxs = train_evidence_ids.apply(lambda x: [evidence_id_dict[evidence_id] for evidence_id in x])\n",
        "\n",
        "dev_claims_text = dev_claims['claim_text']\n",
        "dev_evidence_ids = dev_claims['evidences']\n",
        "dev_evidence_idxs = dev_evidence_ids.apply(lambda x: [evidence_id_dict[evidence_id] for evidence_id in x])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IrTnFcd9Wuo"
      },
      "source": [
        "## 1.2 Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "82z9DJ119Wup",
        "outputId": "8bb9e155-1736-4818-f7da-1db533714e71"
      },
      "outputs": [],
      "source": [
        "#text preprocessing\n",
        "tt = TweetTokenizer()\n",
        "stopwords = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_data(text):\n",
        "    tokens = tt.tokenize(text.lower())\n",
        "\n",
        "    processed_tokens = []\n",
        "\n",
        "    for token in tokens:\n",
        "        token = token.lower()\n",
        "        if token not in stopwords and token.isalpha():\n",
        "            stemmed_token = stemmer.stem(token)\n",
        "            processed_tokens.append(stemmed_token)\n",
        "\n",
        "    return processed_tokens\n",
        "\n",
        "train_claims_text_processed = train_claims_text.apply(preprocess_data)\n",
        "dev_claims_text_precessed = dev_claims_text.apply(preprocess_data)\n",
        "evidence_text_processed = evidence_text.apply(preprocess_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Aw0txwt9Wup"
      },
      "source": [
        "## 1.3 BM25 Scores (For Negative sampling)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rHLO51oC9Wup"
      },
      "outputs": [],
      "source": [
        "# Build inverted index\n",
        "def build_inverted_index(documents):\n",
        "    inverted_index = defaultdict(list)\n",
        "    for i, doc in enumerate(documents):\n",
        "        term_freq = defaultdict(int)\n",
        "        for term in doc:\n",
        "            term_freq[term] += 1\n",
        "        for term, freq in term_freq.items():\n",
        "            inverted_index[term].append((i, freq))\n",
        "    return inverted_index\n",
        "\n",
        "# Compute IDF values\n",
        "def compute_idf_values(inverted_index, total_documents):\n",
        "    idf_values = {}\n",
        "    for term, postings in inverted_index.items():\n",
        "        idf_values[term] = np.log((total_documents + 1) / (len(postings) + 1))\n",
        "    return idf_values\n",
        "\n",
        "# Calculate average document length\n",
        "def calculate_avg_doc_length(documents):\n",
        "    total_length = sum(len(doc) for doc in documents)\n",
        "    return total_length / len(documents)\n",
        "#k.1.0, b = 0.78 recall=0.14\n",
        "# Compute BM25 scores\n",
        "def bm25_scores(query, inverted_index, idf_values, avg_doc_length, k1=0.4, b=0.9):\n",
        "    scores = defaultdict(float)\n",
        "    for term in query:\n",
        "        if term not in inverted_index:\n",
        "            continue\n",
        "        doc_list = inverted_index[term]\n",
        "        idf = idf_values[term]\n",
        "        for doc_id, tf in doc_list:\n",
        "            # Compute BM25 score for this document\n",
        "            doc_length = len(evidence_text_processed[doc_id])\n",
        "            numerator = idf * tf * (k1 + 1)\n",
        "            denominator = tf + k1 * (1 - b + b * (doc_length / avg_doc_length))\n",
        "            scores[doc_id] += numerator / denominator\n",
        "    return scores\n",
        "\n",
        "# Build inverted index for evidence text\n",
        "inverted_index = build_inverted_index(evidence_text_processed)\n",
        "total_documents = len(evidence_text_processed)\n",
        "idf_values = compute_idf_values(inverted_index, total_documents)\n",
        "avg_doc_length = calculate_avg_doc_length(evidence_text_processed)\n",
        "\n",
        "# Example usage\n",
        "train_bm25_results = []\n",
        "for query in train_claims_text_processed:\n",
        "    scores = bm25_scores(query, inverted_index, idf_values, avg_doc_length)\n",
        "    train_bm25_results.append(scores)\n",
        "\n",
        "dev_bm25_results = []\n",
        "for query in dev_claims_text_precessed:\n",
        "    scores = bm25_scores(query, inverted_index, idf_values, avg_doc_length)\n",
        "    dev_bm25_results.append(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XJNfW9SJ9Wup"
      },
      "outputs": [],
      "source": [
        "train_reranked_indices = [[doc_id for doc_id, _ in sorted(scores.items(), key=lambda x: x[1], reverse=True)] for scores in train_bm25_results]\n",
        "train_reranked_scores = [[score for _, score in sorted(scores.items(), key=lambda x: x[1], reverse=True)] for scores in train_bm25_results]\n",
        "\n",
        "dev_reranked_indices = [[doc_id for doc_id, _ in sorted(scores.items(), key=lambda x: x[1], reverse=True)] for scores in dev_bm25_results]\n",
        "dev_reranked_scores = [[score for _, score in sorted(scores.items(), key=lambda x: x[1], reverse=True)] for scores in dev_bm25_results]\n",
        "\n",
        "def topk_indices(indices, k=100):\n",
        "    return [indices[i][:min(k, len(indices[i]))] for i in range(len(indices))]\n",
        "\n",
        "train_top_indices = topk_indices(train_reranked_indices, k=50)\n",
        "dev_top_indices = topk_indices(dev_reranked_indices, k=50)\n",
        "dev_top_scores = topk_indices(dev_reranked_scores, k=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRNKezPQ9Wup"
      },
      "outputs": [],
      "source": [
        "def calculate_average_recall(top_k_indices, true_indices):\n",
        "\n",
        "    recall_values = []\n",
        "\n",
        "    # Iterate over each pair of top_k_indices and corresponding true indices\n",
        "    for top_indices, true_inds in zip(top_k_indices, true_indices):\n",
        "        # Calculate the number of true positives\n",
        "        true_positives = len(set(top_indices) & set(true_inds))\n",
        "\n",
        "        # Calculate recall for this claim\n",
        "        recall = true_positives / len(true_inds) if true_inds else 0  # Avoid division by zero\n",
        "\n",
        "        # Append the recall for this claim to the list\n",
        "        recall_values.append(recall)\n",
        "\n",
        "    # Compute average recall over all claims\n",
        "    avg_recall = sum(recall_values) / len(recall_values) if recall_values else 0  # Avoid division by zero if list is empty\n",
        "\n",
        "    return avg_recall\n",
        "\n",
        "avg_recall = calculate_average_recall(dev_top_indices, dev_evidence_idxs)\n",
        "print(\"Average Recall:\", avg_recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "UiGozsx3hMON"
      },
      "outputs": [],
      "source": [
        "def build_vocab(texts, min_freq=3):\n",
        "    # Count all the words\n",
        "    word_freq = Counter()\n",
        "    for text in texts:\n",
        "        word_freq.update(text)\n",
        "\n",
        "    # Start vocab from special tokens\n",
        "    vocab = OrderedDict({\n",
        "        \"<pad>\": 0,\n",
        "        \"<unk>\": 1,\n",
        "        \"<sos>\": 2,\n",
        "        \"<eos>\": 3\n",
        "    })\n",
        "    index = 4  # Start indexing from 4 because 0-3 are reserved for special tokens\n",
        "    for word, freq in word_freq.items():\n",
        "        if freq >= min_freq:  # Only include words that meet the frequency threshold\n",
        "            vocab[word] = index\n",
        "            index += 1\n",
        "\n",
        "    return vocab\n",
        "\n",
        "# Build vocabulary using only evidence texts and applying the frequency threshold\n",
        "vocab = build_vocab(evidence_text_processed, min_freq=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcWMPVTU9Wuq"
      },
      "source": [
        "## 1.4 Dataset Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exsBNvCufgYZ"
      },
      "source": [
        "### 1.4.1 In-Batch Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ZAd0TM9zf18z"
      },
      "outputs": [],
      "source": [
        "def text_to_indices(text, vocab):\n",
        "    return [vocab[\"<sos>\"]] + [vocab.get(token, vocab['<unk>']) for token in text] + [vocab[\"<eos>\"]]\n",
        "\n",
        "\n",
        "class RankingDatasetInBatch(Dataset):\n",
        "    def __init__(self, claims, evidences, true_indices):\n",
        "        self.claims = claims\n",
        "        self.evidences = evidences\n",
        "        self.true_indices = true_indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.claims)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pos_idx = random.choice(self.true_indices[idx])  # Randomly sample one positive evidence index\n",
        "        claim = self.claims[idx]\n",
        "        pos_evidence = self.evidences[pos_idx]\n",
        "        return claim, pos_evidence\n",
        "\n",
        "def inbatch_collate_fn(batch):\n",
        "    claims, pos_evidences = zip(*batch)\n",
        "\n",
        "    # Prepare claims and positive evidences\n",
        "    claims_indices = [text_to_indices(claim, vocab) for claim in claims]\n",
        "    pos_indices = [text_to_indices(evidence, vocab) for evidence in pos_evidences]\n",
        "\n",
        "    # Pad sequences for claims and positive evidences\n",
        "    claims_padded = pad_sequence([torch.tensor(ci, dtype=torch.long) for ci in claims_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "    pos_padded = pad_sequence([torch.tensor(pi, dtype=torch.long) for pi in pos_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "\n",
        "    # Generate in-batch negatives: Each claim gets the positive samples of all other claims as its negatives.\n",
        "    neg_padded_list = []\n",
        "    max_length = max([len(pi) for pi in pos_indices])  # Find the maximum length of positive evidences in the batch\n",
        "\n",
        "    for i in range(len(batch)):\n",
        "        neg_samples = [pos_indices[j] for j in range(len(batch)) if i != j]\n",
        "\n",
        "        # Pad each negative sample to the maximum length\n",
        "        neg_padded = [F.pad(torch.tensor(ni, dtype=torch.long), (0, max_length - len(ni)), value=vocab['<pad>']) for ni in neg_samples]\n",
        "        neg_padded_stack = torch.stack(neg_padded, dim=0)\n",
        "        neg_padded_list.append(neg_padded_stack)\n",
        "\n",
        "    # Stack the list of negative batches to form a single tensor\n",
        "    neg_padded_stack = torch.stack(neg_padded_list, dim=0)\n",
        "\n",
        "    return claims_padded, pos_padded, neg_padded_stack\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp3pFas7fl38"
      },
      "source": [
        "### 1.4.2 In-Batch + Top Negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "95zAO4lBf2iP"
      },
      "outputs": [],
      "source": [
        "class RankingDatasetInBatchGold(Dataset):\n",
        "    def __init__(self, claims, evidences, true_indices, top_indices):\n",
        "        self.claims = claims\n",
        "        self.evidences = evidences\n",
        "        self.true_indices = true_indices\n",
        "        self.top_indices = top_indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.claims)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pos_idx = random.choice(self.true_indices[idx])  # Randomly sample one positive evidence index\n",
        "        claim = self.claims[idx]\n",
        "        pos_evidence = self.evidences[pos_idx]\n",
        "\n",
        "        # Sample a negative from the top indices\n",
        "        top_neg_indices = [i for i in self.top_indices[idx] if i not in self.true_indices[idx]]\n",
        "        neg_idx = random.choice(top_neg_indices[:20])  # Choose one from the top 20 indices that are not true indices\n",
        "        neg_evidence = self.evidences[neg_idx]\n",
        "\n",
        "        return claim, pos_evidence, neg_evidence\n",
        "\n",
        "def inbatch_gold_collate_fn(batch):\n",
        "    claims, pos_evidences, neg_evidences = zip(*batch)\n",
        "\n",
        "    # Prepare claims, positive evidences, and sampled negative evidences\n",
        "    claims_indices = [text_to_indices(claim, vocab) for claim in claims]\n",
        "    pos_indices = [text_to_indices(evidence, vocab) for evidence in pos_evidences]\n",
        "    neg_indices = [text_to_indices(evidence, vocab) for evidence in neg_evidences]\n",
        "\n",
        "    # Pad sequences for claims, positive evidences, and sampled negative evidences\n",
        "    claims_padded = pad_sequence([torch.tensor(ci, dtype=torch.long) for ci in claims_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "    pos_padded = pad_sequence([torch.tensor(pi, dtype=torch.long) for pi in pos_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "    neg_padded = pad_sequence([torch.tensor(ni, dtype=torch.long) for ni in neg_indices], batch_first=True, padding_value=vocab['<pad>'])\n",
        "\n",
        "    # Generate in-batch negatives: Each claim gets the positive samples of all other claims as its negatives.\n",
        "    neg_padded_list = []\n",
        "    for i in range(len(batch)):\n",
        "        neg_samples = [pos_indices[j] for j in range(len(batch)) if i != j]\n",
        "        neg_samples.append(neg_indices[i])  # Add the sampled negative evidence for this claim\n",
        "        neg_padded_stack = pad_sequence([torch.tensor(ni, dtype=torch.long) for ni in neg_samples], batch_first=True, padding_value=vocab['<pad>'])\n",
        "        neg_padded_list.append(neg_padded_stack)\n",
        "\n",
        "    # Find the maximum length of the negative sequences in the neg_padded_list\n",
        "    max_length = max([neg.size(1) for neg in neg_padded_list])\n",
        "\n",
        "    # Pad each sequence in the neg_padded_list to the maximum length\n",
        "    neg_padded_list = [F.pad(neg, (0, max_length - neg.size(1)), value=vocab['<pad>']) for neg in neg_padded_list]\n",
        "\n",
        "    # Stack the list of negative batches to form a single tensor\n",
        "    combined_neg_padded_stack = torch.stack(neg_padded_list, dim=0)\n",
        "\n",
        "    return claims_padded, pos_padded, combined_neg_padded_stack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55wRdIAo9Wuq"
      },
      "source": [
        "## 2.1 Transformer Encoder (SiameseNetwork)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QIEqDDT78q39"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, emb_size: int, dropout: float, maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(-torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(0)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: torch.Tensor):\n",
        "        token_embedding = token_embedding + self.pos_embedding[:, :token_embedding.size(1), :]\n",
        "        return self.dropout(token_embedding)\n",
        "\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size: int):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=0)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: torch.Tensor):\n",
        "        embeddings = self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "        return embeddings\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, nhead=8, num_encoder_layers=3, dim_feedforward=512, dropout=0.5):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.token_embedding = TokenEmbedding(vocab_size, embed_dim)\n",
        "        self.pos_encoder = PositionalEncoding(embed_dim, dropout)\n",
        "        self.layer_norm = nn.LayerNorm(embed_dim)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_encoder_layers)\n",
        "        self.attention = nn.MultiheadAttention(embed_dim, nhead, dropout=dropout, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(embed_dim, 1)\n",
        "\n",
        "    def forward(self, src, src_key_padding_mask):\n",
        "        src = self.token_embedding(src)\n",
        "        src = self.pos_encoder(src)\n",
        "        src = self.layer_norm(src)\n",
        "        output = self.transformer_encoder(src, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "        # Apply attention mechanism\n",
        "        attn_output, _ = self.attention(output, output, output, key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "        # Compute attention weights\n",
        "        attn_weights = torch.softmax(self.fc(attn_output), dim=1)\n",
        "\n",
        "        # Compute context vector as a weighted sum of the encoder outputs\n",
        "        context_vector = torch.sum(attn_weights * attn_output, dim=1)\n",
        "\n",
        "        return context_vector\n",
        "\n",
        "class SiameseTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size: int, embed_dim: int, nhead: int = 8, num_encoder_layers: int = 3,\n",
        "                 dim_feedforward: int = 512, dropout: float = 0.5):\n",
        "        super(SiameseTransformer, self).__init__()\n",
        "        self.encoder = TransformerEncoder(vocab_size, embed_dim, nhead, num_encoder_layers, dim_feedforward, dropout)\n",
        "\n",
        "    def forward(self, claims: torch.Tensor, evidences: torch.Tensor):\n",
        "        # Create mask on the fly\n",
        "        claims_mask = (claims == 0)\n",
        "        evidences_mask = (evidences == 0)\n",
        "\n",
        "        claims_enc = self.encoder(claims, claims_mask)\n",
        "        evidences_enc = self.encoder(evidences, evidences_mask)\n",
        "\n",
        "        # Ensure the encodings have the correct dimensions for the operations\n",
        "        claims_enc = claims_enc.unsqueeze(1)\n",
        "        evidences_enc = evidences_enc.unsqueeze(2)\n",
        "\n",
        "        # Compute dot product\n",
        "        scores_dot = torch.bmm(claims_enc, evidences_enc).squeeze()\n",
        "\n",
        "        return scores_dot\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7YMtrx09Wur"
      },
      "source": [
        "## 2.2 Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "dHun-ZWjEf0h"
      },
      "outputs": [],
      "source": [
        "def listwise_loss(model, claims_emb, pos_evidences_emb, neg_evidences_emb):\n",
        "    pos_scores = model(claims_emb, pos_evidences_emb).unsqueeze(1)\n",
        "    neg_scores = torch.stack([model(claims_emb, neg) for neg in neg_evidences_emb.transpose(0, 1)], dim=1)\n",
        "\n",
        "    scores = torch.cat((pos_scores, neg_scores), dim=1)\n",
        "    scores = scores.squeeze(-1)\n",
        "    scores = F.log_softmax(scores, dim=1)\n",
        "\n",
        "    # Create target tensor where the index of positive examples is always 0\n",
        "    target = torch.zeros(scores.size(0), dtype=torch.long, device=scores.device)\n",
        "\n",
        "    return F.nll_loss(scores, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uvGJka2u9Wur"
      },
      "outputs": [],
      "source": [
        "def margin_ranking_loss(model, claims, pos_evidences, neg_evidences, margin=1.5):\n",
        "    batch_size = claims.size(0)\n",
        "\n",
        "    # Get the scores for positive evidence\n",
        "    pos_scores = model(claims, pos_evidences).unsqueeze(1)\n",
        "\n",
        "    # Get the scores for negative evidence\n",
        "    neg_scores_list = [model(claims, neg_evidences[:, i, :]).unsqueeze(1) for i in range(neg_evidences.shape[1])]\n",
        "    neg_scores = torch.cat(neg_scores_list, dim=1)\n",
        "\n",
        "    # Calculate the margin ranking loss\n",
        "    target = torch.ones_like(neg_scores, device=claims.device)\n",
        "    pos_scores = pos_scores.expand_as(neg_scores)  # Expand pos_scores to match neg_scores shape\n",
        "    loss = F.margin_ranking_loss(pos_scores, neg_scores, target, margin=margin)\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK4tCUFy9Wur"
      },
      "source": [
        "## 2.3 Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pf6eC5f-9Wur"
      },
      "outputs": [],
      "source": [
        "def topk_indices(indices, k=100):\n",
        "    return [indices[i][:min(k, len(indices[i]))] for i in range(len(indices))]\n",
        "\n",
        "def evaluate_model(model, claims, evidence_texts, dev_top_indices, top_k, vocab, pad_idx):\n",
        "    # Convert tensors to lists of indices and get the top k indices for evaluation\n",
        "    dev_top_indices = topk_indices(dev_top_indices, k=top_k)\n",
        "\n",
        "    dev_scores = []\n",
        "    for idx in range(len(claims)):\n",
        "        top_k_evidence_idxs = dev_top_indices[idx]\n",
        "        top_k_evidences = [evidence_texts[i] for i in top_k_evidence_idxs]\n",
        "        scores = score_query(model, claims[idx], top_k_evidences, vocab, pad_idx)\n",
        "        dev_scores.append(scores)\n",
        "\n",
        "    reranked_indices = []\n",
        "    for indices, scores in zip(dev_top_indices, dev_scores):\n",
        "        indexed_scores = list(zip(indices, scores))\n",
        "        sorted_by_score = sorted(indexed_scores, key=lambda x: x[1], reverse=True)\n",
        "        sorted_indices = [idx for idx, _ in sorted_by_score]\n",
        "        reranked_indices.append(sorted_indices)\n",
        "\n",
        "    return reranked_indices\n",
        "\n",
        "def train_model(model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, eval_fn, eval_data, vocab, pad_idx, topk=20):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"\\n\" + \"#\" * 50)  # Print separation line\n",
        "        print(f\"Starting Epoch {epoch+1}/{num_epochs}\")\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        for batch in dataloader:\n",
        "            if batch is None:\n",
        "                continue\n",
        "\n",
        "            claim, pos_evidences, neg_evidences = batch\n",
        "            claim = claim.to(device)\n",
        "            pos_evidences = pos_evidences.to(device)\n",
        "            neg_evidences = neg_evidences.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model, claim, pos_evidences, neg_evidences)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_epoch_loss = epoch_loss / len(dataloader)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_epoch_loss}')\n",
        "\n",
        "        scheduler.step(avg_epoch_loss)\n",
        "        current_lr = scheduler.optimizer.param_groups[0]['lr']\n",
        "        print(f\"Current Learning Rate: {current_lr}\")\n",
        "\n",
        "        # Evaluation at the end of each epoch\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            reranked_indices = eval_fn(model, eval_data['claims'], eval_data['evidences'], eval_data['top_indices'], top_k=topk, vocab=vocab, pad_idx=pad_idx)\n",
        "            results = evaluate_evidence_retrieval(reranked_indices, eval_data['ground_truth'], k=5)\n",
        "            print(f\"Epoch {epoch+1} Evaluation - Recall: {results['average_recall']}, Precision: {results['average_precision']}, F1 Score: {results['average_fscore']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B311yWnNbaV0"
      },
      "source": [
        "### 2.3.1 Transformer + Listwise"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpDYcPwooeh8"
      },
      "source": [
        "#### In Batch Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1O80nHyoi52",
        "outputId": "1f366875-5bd3-48c0-d69d-8c532e92d72b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/10\n",
            "Epoch 1/10, Average Loss: 3.9917064874600143\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.07380952380952381, Precision: 0.04155844155844158, F1 Score: 0.04927849927849929\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/10\n",
            "Epoch 2/10, Average Loss: 3.523068825403849\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.09761904761904758, Precision: 0.05454545454545456, F1 Score: 0.06489383632240775\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/10\n",
            "Epoch 3/10, Average Loss: 3.435410499572754\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.09686147186147183, Precision: 0.05324675324675328, F1 Score: 0.06377551020408163\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/10\n",
            "Epoch 4/10, Average Loss: 3.332676820265941\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.09480519480519478, Precision: 0.049350649350649374, F1 Score: 0.05968357039785613\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/10\n",
            "Epoch 5/10, Average Loss: 3.3012423576452794\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.10216450216450215, Precision: 0.06103896103896104, F1 Score: 0.07178416821273965\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 6/10\n",
            "Epoch 6/10, Average Loss: 3.273968287003346\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 6 Evaluation - Recall: 0.08906926406926408, Precision: 0.049350649350649374, F1 Score: 0.05876623376623377\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 7/10\n",
            "Epoch 7/10, Average Loss: 3.1669538082220616\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 7 Evaluation - Recall: 0.11114718614718613, Precision: 0.058441558441558454, F1 Score: 0.07151618223046798\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 8/10\n",
            "Epoch 8/10, Average Loss: 3.1114796155538316\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 8 Evaluation - Recall: 0.11536796536796536, Precision: 0.06493506493506493, F1 Score: 0.0773088023088023\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 9/10\n",
            "Epoch 9/10, Average Loss: 2.9743568774981375\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 9 Evaluation - Recall: 0.11655844155844153, Precision: 0.06493506493506493, F1 Score: 0.07829313543599258\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 10/10\n",
            "Epoch 10/10, Average Loss: 3.0024424210572853\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 10 Evaluation - Recall: 0.0786796536796537, Precision: 0.049350649350649374, F1 Score: 0.05747268604411463\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#data loading\n",
        "dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "embedding_dim = 320  # Dimension of the embeddings\n",
        "hidden_dim = 256  # Hidden dimension size\n",
        "dropout_rate = 0.5  # Dropout rate\n",
        "nhead = 4  # Number of attention heads\n",
        "num_encoder_layers = 3  # Number of encoder layers\n",
        "dim_feedforward = 512  # Dimension of the feedforward network\n",
        "\n",
        "transformer_model = SiameseTransformer(\n",
        "    vocab_size=len(vocab),\n",
        "    embed_dim=embedding_dim,\n",
        "    nhead=nhead,\n",
        "    num_encoder_layers=num_encoder_layers,\n",
        "    dim_feedforward=dim_feedforward,\n",
        "    dropout=dropout_rate\n",
        ").to(device)\n",
        "\n",
        "criterion = listwise_loss\n",
        "optimizer = optim.Adam(transformer_model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(transformer_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASUtAb3iojUn"
      },
      "source": [
        "#### In Batch + Gold Negatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFmU3E8zoof7",
        "outputId": "7e2fb0f2-6ada-4735-9514-048bcf7fb06b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/10\n",
            "Epoch 1/10, Average Loss: 3.825396770086044\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.12153679653679648, Precision: 0.06233766233766236, F1 Score: 0.07546382189239334\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/10\n",
            "Epoch 2/10, Average Loss: 3.764690276903984\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.07597402597402597, Precision: 0.04545454545454548, F1 Score: 0.053607503607503604\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/10\n",
            "Epoch 3/10, Average Loss: 3.7049001180208645\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.08906926406926406, Precision: 0.049350649350649374, F1 Score: 0.05984848484848485\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/10\n",
            "Epoch 4/10, Average Loss: 3.67350295262459\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.09480519480519481, Precision: 0.049350649350649374, F1 Score: 0.0607658214801072\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/10\n",
            "Epoch 5/10, Average Loss: 3.660590465252216\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.0696969696969697, Precision: 0.048051948051948075, F1 Score: 0.055215419501133796\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 6/10\n",
            "Epoch 6/10, Average Loss: 3.638963155257396\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 6 Evaluation - Recall: 0.08658008658008658, Precision: 0.05454545454545456, F1 Score: 0.06305400948258091\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 7/10\n",
            "Epoch 7/10, Average Loss: 3.602638073456593\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 7 Evaluation - Recall: 0.07857142857142856, Precision: 0.04545454545454548, F1 Score: 0.05362811791383221\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 8/10\n",
            "Epoch 8/10, Average Loss: 3.627184134263259\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 8 Evaluation - Recall: 0.07002164502164503, Precision: 0.04025974025974028, F1 Score: 0.048196248196248195\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 9/10\n",
            "Epoch 9/10, Average Loss: 3.576120761724619\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 9 Evaluation - Recall: 0.07532467532467532, Precision: 0.04675324675324677, F1 Score: 0.054478458049886644\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 10/10\n",
            "Epoch 10/10, Average Loss: 3.562003630858201\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 10 Evaluation - Recall: 0.0951298701298701, Precision: 0.05844155844155844, F1 Score: 0.06706864564007421\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#data loading\n",
        "dataset = RankingDatasetInBatchGold(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_gold_collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "embedding_dim = 320  # Dimension of the embeddings\n",
        "hidden_dim = 512  # Hidden dimension size\n",
        "dropout_rate = 0.7  # Dropout rate\n",
        "nhead = 4  # Number of attention heads\n",
        "num_encoder_layers = 3  # Number of encoder layers\n",
        "dim_feedforward = 512  # Dimension of the feedforward network\n",
        "\n",
        "transformer_model = SiameseTransformer(\n",
        "    vocab_size=len(vocab),\n",
        "    embed_dim=embedding_dim,\n",
        "    nhead=nhead,\n",
        "    num_encoder_layers=num_encoder_layers,\n",
        "    dim_feedforward=dim_feedforward,\n",
        "    dropout=dropout_rate\n",
        ").to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "criterion = listwise_loss\n",
        "optimizer = optim.Adam(transformer_model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(transformer_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Prgrt6chcWXT"
      },
      "source": [
        "### 2.3.2 Transformer + MarginRanking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxvT6Q6rsEnY"
      },
      "source": [
        "#### In batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4PGQUDDsHAz",
        "outputId": "0987ae2b-0c73-4c9d-9dd1-ab337151bdc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/5\n",
            "Epoch 1/5, Average Loss: 1.716033208064544\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.09112554112554112, Precision: 0.055844155844155856, F1 Score: 0.0650484436198722\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/5\n",
            "Epoch 2/5, Average Loss: 1.4950196498479598\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.10703463203463204, Precision: 0.058441558441558454, F1 Score: 0.07126881055452484\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/5\n",
            "Epoch 3/5, Average Loss: 1.3984164977684999\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.09426406926406927, Precision: 0.049350649350649374, F1 Score: 0.05950319521748095\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/5\n",
            "Epoch 4/5, Average Loss: 1.330437080982404\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.12012987012987009, Precision: 0.0662337662337662, F1 Score: 0.08016388373531232\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/5\n",
            "Epoch 5/5, Average Loss: 1.1607617476047614\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.11547619047619044, Precision: 0.055844155844155856, F1 Score: 0.06986703772418058\n"
          ]
        }
      ],
      "source": [
        "dataset = RankingDatasetInBatch(train_claims_text_processed, evidence_text_processed, train_evidence_idxs)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_collate_fn)\n",
        "\n",
        "# Initialize model\n",
        "embedding_dim = 320  # Dimension of the embeddings\n",
        "hidden_dim = 128  # Hidden dimension size\n",
        "dropout_rate = 0.5  # Dropout rate\n",
        "nhead = 8  # Number of attention heads\n",
        "num_encoder_layers = 3  # Number of encoder layers\n",
        "dim_feedforward = 512  # Dimension of the feedforward network\n",
        "\n",
        "transformer_model = SiameseTransformer(\n",
        "    vocab_size=len(vocab),\n",
        "    embed_dim=embedding_dim,\n",
        "    nhead=nhead,\n",
        "    num_encoder_layers=num_encoder_layers,\n",
        "    dim_feedforward=dim_feedforward,\n",
        "    dropout=dropout_rate\n",
        ").to(device)\n",
        "\n",
        "criterion = margin_ranking_loss\n",
        "optimizer = optim.Adam(transformer_model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(transformer_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2N_C6PZsJ9D"
      },
      "source": [
        "#### In Batch + Gold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z_KZFiRsKIz",
        "outputId": "a66878cd-7b23-415a-b806-ee85e06b135a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "##################################################\n",
            "Starting Epoch 1/5\n",
            "Epoch 1/5, Average Loss: 1.6735933866256323\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 1 Evaluation - Recall: 0.10064935064935064, Precision: 0.06103896103896103, F1 Score: 0.07212430426716142\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 2/5\n",
            "Epoch 2/5, Average Loss: 1.5162645028187678\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 2 Evaluation - Recall: 0.08419913419913419, Precision: 0.048051948051948075, F1 Score: 0.05796742939600085\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 3/5\n",
            "Epoch 3/5, Average Loss: 1.3628566754169953\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 3 Evaluation - Recall: 0.08116883116883115, Precision: 0.04545454545454548, F1 Score: 0.054473304473304486\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 4/5\n",
            "Epoch 4/5, Average Loss: 1.216034737917093\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 4 Evaluation - Recall: 0.09274891774891772, Precision: 0.05194805194805197, F1 Score: 0.06254895897753042\n",
            "\n",
            "##################################################\n",
            "Starting Epoch 5/5\n",
            "Epoch 5/5, Average Loss: 1.1748007535934448\n",
            "Current Learning Rate: 0.001\n",
            "Epoch 5 Evaluation - Recall: 0.09188311688311689, Precision: 0.05064935064935068, F1 Score: 0.06067821067821069\n"
          ]
        }
      ],
      "source": [
        "dataset = RankingDatasetInBatchGold(train_claims_text_processed, evidence_text_processed, train_evidence_idxs, train_top_indices)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=inbatch_gold_collate_fn)\n",
        "# Initialize model\n",
        "# Initialize model\n",
        "embedding_dim = 320  # Dimension of the embeddings\n",
        "hidden_dim = 128  # Hidden dimension size\n",
        "dropout_rate = 0.5  # Dropout rate\n",
        "nhead = 8  # Number of attention heads\n",
        "num_encoder_layers = 3  # Number of encoder layers\n",
        "dim_feedforward = 512  # Dimension of the feedforward network\n",
        "\n",
        "transformer_model = SiameseTransformer(\n",
        "    vocab_size=len(vocab),\n",
        "    embed_dim=embedding_dim,\n",
        "    nhead=nhead,\n",
        "    num_encoder_layers=num_encoder_layers,\n",
        "    dim_feedforward=dim_feedforward,\n",
        "    dropout=dropout_rate\n",
        ").to(device)\n",
        "\n",
        "criterion = margin_ranking_loss\n",
        "optimizer = optim.Adam(transformer_model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
        "\n",
        "clip_value = 1.0\n",
        "\n",
        "num_epochs = 5\n",
        "\n",
        "eval_data = {\n",
        "    'claims': dev_claims_text_precessed,\n",
        "    'evidences': evidence_text_processed,\n",
        "    'top_indices': dev_top_indices,\n",
        "    'ground_truth': dev_evidence_idxs\n",
        "}\n",
        "\n",
        "\n",
        "train_model(transformer_model, dataloader, criterion, optimizer, scheduler, device, num_epochs, clip_value, evaluate_model, eval_data, vocab, vocab['<pad>'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6ZVeNYIH9IaL"
      },
      "outputs": [],
      "source": [
        "def score_query(model, query, evidences, vocab, pad_idx):\n",
        "    # Convert query and evidences to indices using the same function as during training\n",
        "    query_indices = text_to_indices(query, vocab)  # Query to indices\n",
        "    evidence_indices = [text_to_indices(evidence, vocab) for evidence in evidences]  # Evidences to indices\n",
        "\n",
        "    # Convert lists to tensors and pad\n",
        "    query_tensor = pad_sequence([torch.tensor(query_indices)], batch_first=True, padding_value=pad_idx)\n",
        "    evidence_tensors = pad_sequence([torch.tensor(ei) for ei in evidence_indices], batch_first=True, padding_value=pad_idx)\n",
        "\n",
        "    query_tensor = query_tensor.to(device)\n",
        "    evidence_tensors = evidence_tensors.to(device)\n",
        "\n",
        "    # Set the model to evaluation mode and disable gradient computation\n",
        "    model.eval()\n",
        "    scores = []\n",
        "    with torch.no_grad():\n",
        "        # Process all evidences in one batch for efficiency\n",
        "        for i in range(evidence_tensors.shape[0]):\n",
        "            score = model(query_tensor, evidence_tensors[i].unsqueeze(0))\n",
        "            scores.append(score.item())\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "76a6ujov_Rt7"
      },
      "outputs": [],
      "source": [
        "def evaluate_evidence_retrieval(predicted_indices_list, actual_indices_list, k=5):\n",
        "    assert len(predicted_indices_list) == len(actual_indices_list), \"Both inputs must have the same length.\"\n",
        "\n",
        "    total_recall = 0.0\n",
        "    total_precision = 0.0\n",
        "    total_fscore = 0.0\n",
        "    num_claims = len(predicted_indices_list)\n",
        "\n",
        "    for predicted_indices, actual_indices in zip(predicted_indices_list, actual_indices_list):\n",
        "        # Convert tensors in predicted_indices to integers if they are not already\n",
        "        predicted_indices = [index.item() if isinstance(index, torch.Tensor) else index for index in predicted_indices]\n",
        "\n",
        "        # Retrieve the top k predictions\n",
        "        top_k_predicted = set(predicted_indices[:k])\n",
        "        actual_indices_set = set(actual_indices)\n",
        "\n",
        "        # Calculate the number of correct predictions\n",
        "        correct_predictions = len(top_k_predicted.intersection(actual_indices_set))\n",
        "\n",
        "        # Calculate metrics\n",
        "        if correct_predictions > 0:\n",
        "            recall = float(correct_predictions) / len(actual_indices_set)\n",
        "            precision = float(correct_predictions) / k\n",
        "            if (precision + recall) != 0:\n",
        "                fscore = 2 * (precision * recall) / (precision + recall)\n",
        "            else:\n",
        "                fscore = 0.0\n",
        "        else:\n",
        "            recall = 0.0\n",
        "            precision = 0.0\n",
        "            fscore = 0.0\n",
        "\n",
        "        # Accumulate the metrics to calculate averages later\n",
        "        total_recall += recall\n",
        "        total_precision += precision\n",
        "        total_fscore += fscore\n",
        "\n",
        "    # Calculate average metrics\n",
        "    average_recall = total_recall / num_claims\n",
        "    average_precision = total_precision / num_claims\n",
        "    average_fscore = total_fscore / num_claims\n",
        "\n",
        "    return {\n",
        "        \"average_recall\": average_recall,\n",
        "        \"average_precision\": average_precision,\n",
        "        \"average_fscore\": average_fscore\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
